{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e951a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c866d4-0501-4ada-ad27-06d49e8de239",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0658fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6370 images belonging to 3 classes.\n",
      "Found 9394 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 設置數據生成器\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    ")\n",
    "\n",
    "# 訓練數據生成器\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'E:\\Codes\\CV train\\回收系統dataset\\train',  # 替換為您的資料路徑\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "# 驗證數據生成器\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    r'E:\\Codes\\CV train\\回收系統dataset\\TrashBox',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5d9f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If imagenet weights are being loaded, alpha can be one of `0.35`, `0.50`, `0.75`, `1.0`, `1.3` or `1.4` only.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 加載預訓練模型\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mMobileNetV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 添加自定義分類層\u001b[39;00m\n\u001b[0;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\applications\\mobilenet_v2.py:291\u001b[0m, in \u001b[0;36mMobileNetV2\u001b[1;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    290\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.35\u001b[39m, \u001b[38;5;241m0.50\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.3\u001b[39m, \u001b[38;5;241m1.4\u001b[39m]:\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf imagenet weights are being loaded, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    292\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha can be one of `0.35`, `0.50`, `0.75`, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    293\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`1.0`, `1.3` or `1.4` only.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m rows \u001b[38;5;241m!=\u001b[39m cols \u001b[38;5;129;01mor\u001b[39;00m rows \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m192\u001b[39m, \u001b[38;5;241m224\u001b[39m]:\n\u001b[0;32m    296\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: If imagenet weights are being loaded, alpha can be one of `0.35`, `0.50`, `0.75`, `1.0`, `1.3` or `1.4` only."
     ]
    }
   ],
   "source": [
    "# 加載預訓練模型\n",
    "base_model = MobileNetV2(\n",
    "    alpha=0.35,\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3))\n",
    "\n",
    "# 添加自定義分類層\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# 構建完整模型\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# 解凍預訓練層\n",
    "for layer in base_model.layers:#[:-3]\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "# 編譯模型\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb439079-291a-44f0-892f-4e3d757dc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"test.h5\",   # 保存的文件名稱\n",
    "    monitor=\"val_accuracy\",  # 監測驗證準確率（也可以改成 \"val_loss\"）\n",
    "    save_best_only=True,     # 只儲存最佳權重\n",
    "    mode=\"max\",              # \"max\" 代表數值越高越好（適用於準確率）\n",
    "    verbose=1                # 顯示存檔訊息\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d644a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=train_generator.samples // 16,\n",
    "    validation_steps=validation_generator.samples // 16,\n",
    "    callbacks=[checkpoint]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9874a-8887-4f4d-9bbd-722230599a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a15d1-a09b-4496-a7cb-0791e4ede0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_model: 7385\n",
    "#VGG16: 8702\n",
    "#VGG19: 8686\n",
    "#ResNet50: 5409\n",
    "#ResNet101: 5729\n",
    "#ResNet152: 5881\n",
    "#MobileNet: 9319\n",
    "#MobileNetV2: 9223\n",
    "#MobileNetV3Large: 5208\n",
    "#MobileNetV3Small: 5304\n",
    "#DenseNet201: 9407\n",
    "#Xception: 9407\n",
    "#NASNetMobile: 9183\n",
    "#NASNetLarge: 9439\n",
    "#EfficientNetB0: 5240\n",
    "#EfficientNetB4: 5224\n",
    "#EfficientNetB7: 5232\n",
    "#InceptionResNetV2: 9327\n",
    "#InceptionV3: 9215\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
