{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f709482f-8d8e-437a-a83d-203b83db17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6370 images belonging to 3 classes.\n",
      "Found 9394 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "Step 0, Loss: [14.489811 14.579288 13.993038 14.33701  14.089329 14.535907 14.314287\n",
      " 13.984363 14.355761 14.192928 14.199024 14.429907 14.08404  14.486324\n",
      " 14.307125 14.005787]\n",
      "Step 10, Loss: [14.013374  14.283559  14.2919855 14.093738  14.576868  14.231466\n",
      " 14.109308  14.2658205 14.449     14.280907  14.3002205 14.599022\n",
      " 14.652584  13.82783   15.019039  14.262299 ]\n",
      "Step 20, Loss: [14.350805  14.108237  14.687073  13.890065  14.574833  14.845942\n",
      " 14.206521  14.189568  14.3220215 14.425041  14.208998  14.265815\n",
      " 14.41795   14.395954  14.309627  14.465677 ]\n",
      "Step 30, Loss: [14.553475 14.521157 14.759769 14.206756 14.267199 14.225507 14.215296\n",
      " 14.347721 14.050127 14.148804 14.269066 14.02713  14.086663 14.281988\n",
      " 14.49991  14.056877]\n",
      "Step 40, Loss: [14.211646  14.382012  14.287823  14.59356   14.315852  14.37658\n",
      " 14.458922  14.451364  14.3333435 14.67121   14.255772  14.06497\n",
      " 14.457702  14.5163965 14.517456  14.458557 ]\n",
      "Step 50, Loss: [14.154094  14.407387  14.376246  14.378129  14.412207  14.076286\n",
      " 14.1335335 14.595716  15.152913  14.900418  14.812811  14.2171955\n",
      " 14.706837  14.070266  14.066833  14.19202  ]\n",
      "Step 60, Loss: [14.186239 14.365721 14.209128 14.45936  14.212641 14.642644 14.041027\n",
      " 14.116611 14.323582 14.318544 14.26942  14.402243 14.368384 14.067323\n",
      " 14.245385 14.819407]\n",
      "Step 70, Loss: [14.474272  14.293131  14.668514  13.939376  14.120322  14.662368\n",
      " 14.339062  14.1416645 14.307971  14.124775  14.126022  14.631614\n",
      " 14.463339  14.854     14.660287  14.183785 ]\n",
      "Step 80, Loss: [14.295629 14.592127 14.529127 14.638201 14.399971 14.774499 14.409195\n",
      " 14.324007 14.391746 14.360887 14.277846 14.716915 14.336807 14.098845\n",
      " 14.988563 14.416929]\n",
      "Step 90, Loss: [14.52508  14.874696 14.848466 14.496868 14.910081 14.158972 14.043477\n",
      " 14.407863 14.125489 14.621681 14.002672 14.442064 14.601582 14.250203\n",
      " 14.001481 14.185794]\n",
      "Step 100, Loss: [14.377179 14.997498 14.696987 14.435696 14.547231 14.111906 14.527531\n",
      " 14.624118 14.305577 14.362046 14.469107 14.650768 14.228925 14.398584\n",
      " 14.371141 14.645989]\n",
      "Step 110, Loss: [14.283057  14.342868  14.333007  14.109396  15.087036  14.419699\n",
      " 14.246918  14.546106  14.194853  14.457941  14.233617  14.186163\n",
      " 14.404607  14.2242    14.092767  14.6705475]\n",
      "Step 120, Loss: [14.064962  14.269366  14.463932  14.205369  14.330197  14.336961\n",
      " 14.489901  14.2709055 14.444123  13.9492655 14.444262  14.359671\n",
      " 14.745578  14.306957  14.16413   14.2057705]\n",
      "Step 130, Loss: [14.456116 14.002271 14.086574 14.155961 15.053992 14.673408 14.605848\n",
      " 14.574983 14.123742 14.270876 14.284524 14.432729 14.459796 14.02403\n",
      " 14.392505 14.170492]\n",
      "Step 140, Loss: [14.259707  13.902562  14.18206   14.653249  13.934448  14.2601185\n",
      " 14.136306  14.24878   14.678595  14.229717  14.178589  14.335006\n",
      " 14.205385  14.069448  14.440344  14.473963 ]\n",
      "Step 150, Loss: [14.564005 14.690889 14.258742 14.441576 14.208879 14.115921 14.233897\n",
      " 14.441832 14.493099 14.253663 14.637278 14.453244 14.061991 14.956347\n",
      " 14.582342 14.543867]\n",
      "Step 160, Loss: [14.506032  14.551349  14.074081  14.692565  14.6545315 14.21634\n",
      " 14.486426  14.332097  14.08881   14.707176  14.324314  13.980316\n",
      " 14.898077  14.235732  14.463781  14.439548 ]\n",
      "Step 170, Loss: [14.282273 15.076076 14.385909 14.326927 14.048527 14.339481 14.455421\n",
      " 14.147936 14.300877 14.624018 14.368521 14.206132 14.84004  14.026571\n",
      " 14.330252 14.060767]\n",
      "Step 180, Loss: [14.213314  14.545943  14.321735  14.5208235 13.923822  14.638783\n",
      " 14.254627  14.400669  14.685988  14.224236  14.723759  14.492125\n",
      " 14.564874  14.28025   14.729263  14.356108 ]\n",
      "Step 190, Loss: [14.388987 14.245507 14.235302 14.513482 14.432726 14.109315 14.388301\n",
      " 14.702709 14.775635 14.437853 14.5255   14.166213 14.360251 14.40538\n",
      " 14.506506 14.431358]\n",
      "Step 200, Loss: [14.150316 14.48592  14.176002 14.417996 14.059564 14.11368  14.501444\n",
      " 14.255769 14.376282 13.966568 14.362061 14.413037 14.479604 14.490527\n",
      " 14.34044  14.289478]\n",
      "Step 210, Loss: [14.096343  14.591365  14.754255  14.412713  14.198056  14.695627\n",
      " 14.004899  14.2452    14.163975  14.271871  14.413513  14.5497265\n",
      " 14.258296  14.533337  14.735905  14.126632 ]\n",
      "Step 220, Loss: [14.631787 14.436881 14.399411 14.634214 15.071976 14.270914 14.715202\n",
      " 14.014549 14.601719 14.197816 14.260368 14.003947 14.350407 14.366407\n",
      " 14.085576 14.198046]\n",
      "Step 230, Loss: [14.491642 14.253145 14.389315 14.341258 14.412369 15.166246 14.18994\n",
      " 14.345428 14.420643 14.57197  14.656781 14.506629 14.206564 14.718038\n",
      " 14.01995  14.252358]\n",
      "Step 240, Loss: [14.578885 14.137979 14.128659 14.398852 14.367554 14.143771 14.519995\n",
      " 13.95628  14.428018 14.329607 14.510876 14.837857 14.338074 14.220716\n",
      " 13.955076 14.257739]\n",
      "Step 250, Loss: [14.9834385 13.948411  14.275626  14.152905  14.586205  14.246152\n",
      " 14.125157  14.998656  14.412532  14.367809  13.9557085 14.966316\n",
      " 14.408029  14.941689  14.404994  13.982386 ]\n",
      "Step 260, Loss: [14.661212  14.138158  14.521357  14.105671  14.029631  14.665385\n",
      " 14.662505  14.62499   14.541575  14.28191   14.265337  14.182779\n",
      " 14.4374275 14.230962  14.264259  14.628136 ]\n",
      "Step 270, Loss: [14.723125  14.094695  14.111591  14.119259  14.695806  14.314183\n",
      " 14.837227  14.461629  14.203705  14.75788   14.172465  14.187979\n",
      " 14.478074  14.543667  14.570972  14.2213335]\n",
      "Step 280, Loss: [14.51675  14.451738 14.221757 14.070723 14.076897 14.492729 14.387169\n",
      " 14.378536 14.121281 14.202413 14.324995 14.141383 14.158952 14.331824\n",
      " 14.502394 14.387093]\n",
      "Step 290, Loss: [14.165742 14.9434   14.03914  14.091412 14.825296 14.615871 14.066189\n",
      " 14.413093 14.190925 15.014779 14.167398 14.287437 14.454631 14.465059\n",
      " 14.012674 14.54673 ]\n",
      "Step 300, Loss: [14.18345  14.363722 14.788296 13.910602 14.330992 14.203263 14.593862\n",
      " 14.307321 14.806962 14.496605 14.941348 14.023479 14.416217 14.271541\n",
      " 14.084599 14.301838]\n",
      "Step 310, Loss: [14.421141 14.564059 14.313981 14.137703 14.486294 14.346364 14.220222\n",
      " 14.755033 14.176323 14.21346  14.547094 14.448189 14.744661 14.389341\n",
      " 14.756041 15.023145]\n",
      "Step 320, Loss: [14.295808 14.398323 14.390371 14.188186 14.44987  14.648463 14.785879\n",
      " 14.099835 14.539238 14.415638 14.362041 14.256181 14.48715  14.539577\n",
      " 14.181318 14.178444]\n",
      "Step 330, Loss: [14.389527 13.952624 14.032625 14.460177 13.963182 14.914913 14.528189\n",
      " 14.180578 14.398785 14.399916 14.562647 13.992793 14.59879  14.660189\n",
      " 14.354013 14.169587]\n",
      "Step 340, Loss: [14.140121  14.35347   14.570336  14.310878  14.948683  14.708177\n",
      " 14.34877   14.6298685 14.5225525 14.368252  14.607658  14.437693\n",
      " 14.669308  14.480431  14.341459  15.272602 ]\n",
      "Step 350, Loss: [14.268837  14.355437  14.126993  14.533457  14.514541  14.225784\n",
      " 14.2997465 14.305305  14.411643  14.55014   14.51148   14.513797\n",
      " 14.528051  14.3037615 14.185821  14.301677 ]\n",
      "Step 360, Loss: [14.089985  14.637009  14.231247  14.137343  14.10716   14.59188\n",
      " 14.152171  14.517365  14.190543  15.079932  14.308963  14.265731\n",
      " 14.073717  14.208991  14.2536955 14.319109 ]\n",
      "Step 370, Loss: [14.116133 13.992686 14.443439 14.550222 14.575758 14.254446 14.021674\n",
      " 14.219569 14.057631 14.546495 14.204932 14.409888 14.45106  14.205018\n",
      " 14.586226 14.390683]\n",
      "Step 380, Loss: [14.288195 14.583285 14.230363 14.54749  14.769859 14.323578 14.520024\n",
      " 14.186011 14.297314 14.39935  14.220535 14.195231 14.305923 14.196061\n",
      " 14.461077 14.057088]\n",
      "Step 390, Loss: [14.390952 13.939715 14.451564 14.192328 14.453843 14.106463 14.45092\n",
      " 14.471617 14.134768 14.171388 14.160675 14.504041 14.900179 14.397104\n",
      " 14.069263 14.433409]\n",
      "Epoch 2/10\n",
      "Step 0, Loss: [14.760674  14.84003   14.712701  14.184311  14.413542  14.450293\n",
      " 14.237325  14.450855  14.381537  14.2247505 14.248922  14.164784\n",
      " 14.331035  14.022005  14.4043    14.035475 ]\n",
      "Step 10, Loss: [15.071147  14.198742  14.247087  14.198659  14.774895  14.569006\n",
      " 14.415521  14.18113   14.844017  14.335019  14.4070635 14.488794\n",
      " 14.487385  14.262449  14.568552  14.234501 ]\n",
      "Step 20, Loss: [14.458029  14.18939   14.479536  14.138148  14.113043  13.947936\n",
      " 13.996094  14.267717  14.334073  14.0004635 14.000181  14.447525\n",
      " 14.445304  14.226241  14.64578   14.186665 ]\n",
      "Step 30, Loss: [14.240123  14.291291  14.913559  14.75672   14.792064  14.865738\n",
      " 14.464818  14.655998  14.345011  14.880738  14.298839  14.1498375\n",
      " 14.11357   14.458052  14.709205  14.038254 ]\n",
      "Step 40, Loss: [14.691201  14.420751  13.945934  13.919069  14.659389  14.258153\n",
      " 14.506242  14.194796  14.1107025 14.37803   14.536516  14.380124\n",
      " 14.414985  14.318009  14.090245  14.332092 ]\n",
      "Step 50, Loss: [14.239106  14.695691  14.079601  14.332313  14.3322    14.4313545\n",
      " 14.250009  14.131594  14.246736  13.974967  14.412438  14.620754\n",
      " 14.808132  14.12593   14.258949  14.36989  ]\n",
      "Step 60, Loss: [14.087718  15.203606  14.229657  14.323139  14.873207  14.059217\n",
      " 14.5931225 14.11364   15.026701  15.200154  14.086657  14.571216\n",
      " 14.310688  14.441507  14.442351  14.512725 ]\n",
      "Step 70, Loss: [14.613118 14.677507 14.356189 14.595712 14.477426 14.661728 14.623351\n",
      " 14.961293 14.013905 14.30969  14.155782 14.119819 14.749204 14.48673\n",
      " 14.449265 14.276684]\n",
      "Step 80, Loss: [14.271557 14.62191  14.245995 14.643413 14.236186 14.431643 14.400613\n",
      " 13.922919 14.11081  14.405146 14.60334  14.515682 14.021329 14.142348\n",
      " 14.400616 14.158667]\n",
      "Step 90, Loss: [14.565429  14.363376  14.209389  13.9507475 14.446535  14.137024\n",
      " 14.379901  14.405032  14.363725  14.361807  14.554257  14.388755\n",
      " 14.49225   14.46272   13.90813   14.716598 ]\n",
      "Step 100, Loss: [14.304251 14.518384 14.44751  14.68768  14.819763 14.323131 14.439775\n",
      " 14.395651 14.543993 14.561157 14.25172  14.497418 14.384761 14.022461\n",
      " 14.306469 14.64477 ]\n",
      "Step 110, Loss: [15.057685  14.248463  14.3819065 14.084594  14.333716  14.131805\n",
      " 14.548674  14.570799  14.256906  15.249135  14.282391  14.115794\n",
      " 15.210299  14.561188  14.534274  14.230268 ]\n",
      "Step 120, Loss: [14.480704  14.517112  14.621495  14.574801  14.322279  14.114248\n",
      " 14.31284   14.1631565 14.328483  14.140391  13.880114  14.2320595\n",
      " 14.854547  14.535521  14.46469   14.528955 ]\n",
      "Step 130, Loss: [14.3839655 14.813233  14.090813  14.180876  14.160488  14.554907\n",
      " 14.617366  14.18347   14.138263  14.314765  14.758711  14.321141\n",
      " 14.139402  14.41104   14.882874  14.244864 ]\n",
      "Step 140, Loss: [14.8671465 14.375854  14.009219  13.987073  14.383061  14.120662\n",
      " 14.588591  14.16868   14.40181   14.606823  14.183934  14.549417\n",
      " 14.103008  14.258886  14.533667  14.215137 ]\n",
      "Step 150, Loss: [14.058093 14.494243 14.745185 14.276628 14.765963 14.190737 14.214313\n",
      " 14.551897 14.459321 14.322645 14.217788 14.394425 14.254683 14.581763\n",
      " 14.301664 14.507412]\n",
      "Step 160, Loss: [14.303604 14.350501 14.098116 14.277613 14.674497 14.285965 14.210963\n",
      " 14.634363 14.613041 14.887421 14.449884 14.154524 14.4729   14.990277\n",
      " 14.478564 14.564301]\n",
      "Step 170, Loss: [14.29196   14.088645  14.16618   14.317054  14.177228  14.270532\n",
      " 14.364096  14.137373  13.995622  14.307335  14.605755  14.628714\n",
      " 14.262215  14.986478  14.4328985 13.952518 ]\n",
      "Step 180, Loss: [14.218673  14.179199  14.15073   14.392951  14.03208   14.341969\n",
      " 13.950077  14.593742  14.833494  14.34674   14.1238785 14.312588\n",
      " 14.728224  14.2611475 14.543042  14.662095 ]\n",
      "Step 190, Loss: [14.4234295 14.389419  14.35128   14.198054  14.264899  14.753803\n",
      " 14.027579  14.196899  14.546787  14.194017  14.45314   14.366806\n",
      " 14.260716  14.08649   14.376237  14.175848 ]\n",
      "Step 200, Loss: [14.681187  14.219731  14.273137  14.194185  14.278894  14.450889\n",
      " 14.373803  14.370052  14.431269  15.121254  14.088557  14.817702\n",
      " 14.525672  14.6192045 14.226223  14.23901  ]\n",
      "Step 210, Loss: [14.7232895 14.308619  14.735054  14.323523  14.627109  14.893387\n",
      " 13.972813  14.454206  14.197701  14.142202  14.339726  14.504523\n",
      " 14.393124  14.299132  14.465284  14.468521 ]\n",
      "Step 220, Loss: [14.373014 14.318191 14.519402 14.354095 14.276417 14.652074 14.264853\n",
      " 15.041912 14.524068 14.377521 14.386403 14.336279 14.056761 14.330551\n",
      " 14.295726 14.492009]\n",
      "Step 230, Loss: [14.315011 14.578316 14.17368  14.117555 14.308939 14.542563 14.226244\n",
      " 14.515854 14.747441 14.479902 14.857797 14.119389 14.631283 14.363025\n",
      " 14.148075 14.649191]\n",
      "Step 240, Loss: [14.114313  14.3531685 14.423971  14.384196  14.584846  14.4647875\n",
      " 14.37015   14.271199  14.1946335 14.172785  14.337525  14.511522\n",
      " 14.412817  14.302799  14.148989  14.376279 ]\n",
      "Step 250, Loss: [14.316487 14.343623 14.271415 14.430653 14.33391  14.51683  14.299326\n",
      " 14.341102 14.354    14.367104 14.673135 14.614871 14.446634 14.12728\n",
      " 14.38184  14.485064]\n",
      "Step 260, Loss: [14.526308  14.24221   14.290821  14.145569  13.950657  14.361538\n",
      " 14.545774  14.411779  14.068906  14.465034  14.5245285 13.949556\n",
      " 14.522669  14.234744  14.37405   14.115063 ]\n",
      "Step 270, Loss: [14.2148075 14.551299  14.7901745 14.087025  14.708304  14.481032\n",
      " 14.89872   14.181946  14.337613  14.467498  14.946132  14.505696\n",
      " 14.269127  14.2689085 14.687304  14.820642 ]\n",
      "Step 280, Loss: [14.432421 14.49494  14.587927 14.319896 14.481201 14.059476 14.473293\n",
      " 14.164683 14.35346  14.779752 14.488934 14.826243 14.364346 14.173033\n",
      " 14.083938 14.475947]\n",
      "Step 290, Loss: [14.332389 14.445974 14.106286 14.534669 14.289432 14.300813 14.125815\n",
      " 14.571249 14.104035 14.556173 14.391939 14.196564 14.019179 14.525835\n",
      " 14.708773 14.302959]\n",
      "Step 300, Loss: [14.193434 14.487436 14.24274  14.188507 14.637256 14.517846 14.441963\n",
      " 14.188774 14.585782 14.549015 14.080461 14.069821 15.11347  14.293617\n",
      " 14.077952 14.295286]\n",
      "Step 310, Loss: [14.407047 14.234765 14.566677 14.320704 14.143091 14.131842 14.838894\n",
      " 14.299345 14.520775 14.010899 14.408672 14.240757 14.465569 14.37052\n",
      " 14.443356 14.247175]\n",
      "Step 320, Loss: [14.242746  14.379503  14.537699  14.2657175 14.074045  14.404869\n",
      " 14.1616745 14.391468  14.487594  14.085876  14.631555  14.419088\n",
      " 14.394187  14.118681  14.257078  14.343433 ]\n",
      "Step 330, Loss: [14.452304  13.9616    14.373774  14.529891  14.236269  14.541805\n",
      " 14.601754  14.787568  14.561811  14.489111  14.422308  14.690009\n",
      " 14.955344  14.5985985 14.356805  14.433375 ]\n",
      "Step 340, Loss: [14.046729  14.203695  14.466     14.2737665 14.218848  14.365347\n",
      " 14.4491825 14.357683  14.456959  14.430542  14.371389  14.429736\n",
      " 14.143138  14.305092  14.602933  14.08346  ]\n",
      "Step 350, Loss: [14.659758  14.759851  14.176409  14.134015  14.23794   14.476532\n",
      " 14.189733  14.0349655 14.572992  14.239976  14.352978  14.535089\n",
      " 14.349657  14.675297  14.239619  14.241434 ]\n",
      "Step 360, Loss: [14.295074  14.824763  14.288757  14.254236  14.274592  14.449302\n",
      " 14.359583  14.135409  14.228402  14.498221  14.394505  14.747245\n",
      " 14.283058  14.6325445 14.665551  14.448377 ]\n",
      "Step 370, Loss: [14.368983 13.928064 14.345564 14.373641 14.438104 14.183632 14.271565\n",
      " 14.924351 14.170677 14.321019 14.313173 14.511568 14.389453 14.318065\n",
      " 14.326475 14.145091]\n",
      "Step 380, Loss: [14.581606  14.45729   14.3278265 14.699247  14.11788   14.526666\n",
      " 14.025434  14.474861  14.256     14.312901  14.377419  14.300081\n",
      " 14.507439  14.360305  14.303297  14.232352 ]\n",
      "Step 390, Loss: [14.078109  14.442115  14.124425  14.644926  14.162606  14.165359\n",
      " 14.3307295 14.575628  14.362054  14.877125  14.4468155 14.521158\n",
      " 14.237777  14.683085  14.020439  13.94409  ]\n",
      "Epoch 3/10\n",
      "Step 0, Loss: [15.005357  14.476597  14.368063  14.4389515 14.088781  14.164845\n",
      " 13.921038  14.130617  14.326112  14.427452  14.180907  14.7489605\n",
      " 14.063141  14.696424  14.419583  14.159104 ]\n",
      "Step 10, Loss: [14.705188 14.037862 14.141554 14.251228 14.341245 14.62705  14.29219\n",
      " 14.220812 14.504521 14.237669 14.300846 14.353693 13.953565 14.473734\n",
      " 14.082153 14.408802]\n",
      "Step 20, Loss: [14.187058 14.73736  14.385527 14.836742 14.856804 14.611194 14.089623\n",
      " 14.239653 14.307148 14.858838 14.278369 14.351282 14.721201 14.339029\n",
      " 14.080816 14.435991]\n",
      "Step 30, Loss: [14.138427  14.504659  14.185156  14.248232  14.035342  14.142358\n",
      " 14.277378  14.180179  14.4314785 14.544175  14.465206  14.455322\n",
      " 14.521369  14.655461  13.9753685 14.480097 ]\n",
      "Step 40, Loss: [14.301125  14.261375  13.980867  14.397484  14.246289  14.5001545\n",
      " 14.22451   14.21713   14.6054    14.268211  14.856798  14.182987\n",
      " 14.364969  14.744273  14.487905  15.0770035]\n",
      "Step 50, Loss: [14.384749  14.463999  14.562644  14.212718  14.520607  14.544276\n",
      " 14.381975  14.3994255 14.9040365 14.150435  14.946407  14.537512\n",
      " 13.995372  14.205808  14.238545  14.900612 ]\n",
      "Step 60, Loss: [14.567898  14.7185955 14.7084465 14.029733  14.377148  14.283545\n",
      " 14.394405  14.139835  14.52536   14.307283  14.281272  14.124108\n",
      " 14.34161   14.112058  14.131327  14.217846 ]\n",
      "Step 70, Loss: [13.927391  14.6888275 14.551458  14.493186  14.371843  14.59711\n",
      " 14.605953  14.404816  14.400019  14.343669  14.300016  14.354232\n",
      " 14.277229  14.523892  14.10933   14.122301 ]\n",
      "Step 80, Loss: [14.562277 14.598653 14.228968 14.176233 14.152189 14.379805 14.002203\n",
      " 14.235874 14.426276 14.931215 14.313965 14.15005  14.332076 14.179692\n",
      " 14.397304 14.033105]\n",
      "Step 90, Loss: [14.258077  14.823952  13.925141  14.632242  14.289561  14.323464\n",
      " 14.352362  14.518598  14.442138  14.3273535 14.198593  14.072334\n",
      " 14.553166  14.810177  14.174464  14.423535 ]\n",
      "Step 100, Loss: [14.350676  14.641676  14.500107  14.541934  14.174454  14.63661\n",
      " 14.066569  14.54699   14.166848  14.211522  14.914726  14.219988\n",
      " 14.2066765 15.021664  14.637435  14.127051 ]\n",
      "Step 110, Loss: [14.4226   14.496689 14.185701 14.038584 14.378555 14.245639 14.403337\n",
      " 14.583534 14.658252 14.680902 14.351121 14.357404 14.282986 14.258676\n",
      " 14.39098  14.669165]\n",
      "Step 120, Loss: [14.272464 14.731906 14.11121  14.950277 14.396177 14.100876 13.881815\n",
      " 14.226355 14.570479 14.154743 14.450514 14.191159 14.407917 14.43717\n",
      " 14.421818 14.36278 ]\n",
      "Step 130, Loss: [14.940521  14.835383  14.317468  14.394967  14.109502  14.193714\n",
      " 14.339386  14.712089  14.381477  14.517032  14.534833  14.685532\n",
      " 14.188882  14.892151  14.4521675 14.140863 ]\n",
      "Step 140, Loss: [14.211618 14.295186 14.719776 14.428277 14.330176 14.051599 14.069116\n",
      " 14.575445 14.334366 14.240283 14.331778 14.028417 14.40688  14.673597\n",
      " 14.585746 14.204014]\n",
      "Step 150, Loss: [14.79347  14.404781 14.459373 14.239394 14.437419 14.333833 14.179988\n",
      " 14.297646 14.304957 14.213432 14.342856 14.803846 14.236586 14.249821\n",
      " 14.128918 14.713133]\n",
      "Step 160, Loss: [14.449492 14.032263 14.036341 14.422991 14.340284 14.675063 14.144972\n",
      " 14.358999 14.680007 14.972552 14.219541 14.68832  14.68162  14.304377\n",
      " 14.530532 14.439259]\n",
      "Step 170, Loss: [14.782455  14.752712  14.527893  14.217161  14.081494  14.388652\n",
      " 14.182753  14.367476  14.282979  14.639305  14.291937  14.274817\n",
      " 14.854     14.635671  14.968562  14.5658865]\n",
      "Step 180, Loss: [14.503558  14.095141  14.03583   14.320686  13.969269  13.986921\n",
      " 14.363709  14.447475  14.530378  14.147523  14.365399  14.0188675\n",
      " 14.757686  14.822216  14.653176  14.3565855]\n",
      "Step 190, Loss: [14.484664  13.933462  14.781713  14.841545  14.288449  13.982451\n",
      " 14.677285  14.535424  14.2242985 14.204235  14.06602   14.710472\n",
      " 14.25026   14.4941    14.056957  14.2042265]\n",
      "Step 200, Loss: [14.30468   14.371622  14.242256  14.161429  14.403884  14.593234\n",
      " 14.168634  14.6224785 14.751292  14.224063  14.27828   14.432077\n",
      " 14.662165  14.325066  14.646213  14.326204 ]\n",
      "Step 210, Loss: [14.692587  14.253209  14.279359  14.225095  14.19726   14.68223\n",
      " 14.140944  14.182535  13.9291725 14.6801605 14.953677  14.829707\n",
      " 14.219752  14.628936  14.100183  14.609945 ]\n",
      "Step 220, Loss: [14.772192 14.217731 14.326675 14.849735 14.80062  14.402721 14.376416\n",
      " 14.311048 14.023263 14.079702 14.47938  14.298518 14.47036  14.09363\n",
      " 14.653397 14.712075]\n",
      "Step 230, Loss: [14.467725  14.744242  14.478873  14.17287   14.321615  14.456489\n",
      " 14.869479  14.748834  14.571022  14.284494  14.4887495 13.973315\n",
      " 14.286115  14.132825  14.7919235 14.268739 ]\n",
      "Step 240, Loss: [14.165493  14.290491  14.351091  14.62421   14.34359   14.057706\n",
      " 14.930117  14.20008   14.426831  14.498504  14.683519  14.391758\n",
      " 14.1822195 14.525014  14.588795  14.339151 ]\n",
      "Step 250, Loss: [14.175155  14.238946  14.319578  14.436418  14.276816  14.525931\n",
      " 14.274998  14.3171835 14.29188   14.632836  14.367571  14.066279\n",
      " 14.34258   14.387563  14.316854  14.648741 ]\n",
      "Step 260, Loss: [14.506127  14.066782  14.316447  14.338902  14.4096    14.082744\n",
      " 14.511793  14.210059  14.132046  14.298358  14.2529335 14.196945\n",
      " 14.177435  14.512119  14.312965  13.948718 ]\n",
      "Step 270, Loss: [14.548769 14.325393 14.401358 14.76463  14.003999 14.383915 14.455103\n",
      " 14.721016 14.349592 14.189884 13.985581 14.47721  14.481239 14.485664\n",
      " 14.281516 14.218458]\n",
      "Step 280, Loss: [14.903152  14.314595  14.086923  14.311104  14.252874  14.694796\n",
      " 14.594187  14.283032  14.305154  14.4260845 14.349672  14.516688\n",
      " 14.358002  14.293781  14.748949  14.284208 ]\n",
      "Step 290, Loss: [14.306416  14.171463  13.930935  14.212768  14.179615  14.303314\n",
      " 14.099903  14.584578  14.796389  14.308838  14.211901  14.3866205\n",
      " 14.541252  14.264702  14.233538  14.457073 ]\n",
      "Step 300, Loss: [14.319449 14.46006  14.635181 14.327888 14.440562 14.318823 14.520307\n",
      " 14.795397 14.68572  14.821492 14.389309 14.236927 14.390286 14.486994\n",
      " 14.050384 14.616978]\n",
      "Step 310, Loss: [14.633688  14.5040865 14.591551  14.038023  14.345396  14.211438\n",
      " 14.0514765 14.1982    14.152535  14.415341  14.457482  14.112409\n",
      " 14.630139  13.962239  14.644273  14.15662  ]\n",
      "Step 320, Loss: [14.450671 14.658638 14.211345 14.714645 14.619283 14.221839 13.883219\n",
      " 14.200373 14.175469 14.376441 14.676583 14.243887 14.596345 14.298908\n",
      " 14.14965  14.384508]\n",
      "Step 330, Loss: [14.542199  14.707543  15.074009  14.378087  14.198807  14.102207\n",
      " 14.602653  14.398547  14.255775  14.324497  14.580452  14.077591\n",
      " 14.1462555 14.516707  14.280795  14.944681 ]\n",
      "Step 340, Loss: [14.543735 14.62413  14.520506 14.231716 14.27436  14.506996 14.980487\n",
      " 14.484471 14.187167 14.421335 14.137285 14.156542 14.0191   14.586262\n",
      " 14.110123 14.18698 ]\n",
      "Step 350, Loss: [14.024794 14.403407 14.390467 14.200867 13.882859 14.415607 14.331657\n",
      " 14.11915  14.429651 14.388716 14.555141 14.206356 14.370774 14.888344\n",
      " 14.572347 14.297363]\n",
      "Step 360, Loss: [13.997535 14.23166  14.787399 14.409265 14.714749 14.1755   14.191065\n",
      " 14.836844 14.00748  14.691986 14.393774 14.981831 14.154458 14.324014\n",
      " 14.508583 14.732223]\n",
      "Step 370, Loss: [14.351286  14.665111  14.422691  14.284151  14.39787   14.456155\n",
      " 14.277279  14.524273  14.467193  14.324062  14.263399  14.540781\n",
      " 14.770904  14.679583  14.1978445 14.484912 ]\n",
      "Step 380, Loss: [14.077207  14.266796  14.443358  14.365192  14.516874  14.29914\n",
      " 14.320315  14.330625  14.259769  14.336756  14.078803  14.700074\n",
      " 14.488088  14.238512  14.5421715 14.9481945]\n",
      "Step 390, Loss: [14.267654 14.148938 14.489963 14.0727   14.296899 14.547402 14.354476\n",
      " 14.016315 14.118319 14.298201 14.617205 14.268826 14.290195 14.418566\n",
      " 14.099953 14.296464]\n",
      "Epoch 4/10\n",
      "Step 0, Loss: [14.479349 14.189083 14.583851 14.452008 14.026409 14.165676 14.583682\n",
      " 14.263451 14.503227 14.606725 14.439394 14.520934 13.978219 14.409649\n",
      " 14.474531 14.374704]\n",
      "Step 10, Loss: [14.475199 14.046419 14.263441 14.11072  14.044328 14.414286 14.388559\n",
      " 14.444718 14.40546  14.265451 14.251752 14.447676 15.216043 13.915849\n",
      " 14.221708 14.543241]\n",
      "Step 20, Loss: [14.44019  14.545222 14.332212 14.107125 14.31762  14.323165 14.585401\n",
      " 14.14226  14.263264 14.172224 14.187761 14.672103 14.319007 13.89722\n",
      " 14.087064 14.33831 ]\n",
      "Step 30, Loss: [14.190303  13.992187  14.312955  14.943643  14.286139  14.66993\n",
      " 14.850052  14.323316  14.31485   14.759725  14.4717865 14.195215\n",
      " 14.528256  14.8738    14.350195  14.893929 ]\n",
      "Step 40, Loss: [14.341978  14.441559  14.148099  15.156067  14.861514  14.152459\n",
      " 14.470545  14.1168165 14.884261  14.306965  14.675856  15.190153\n",
      " 14.6144    14.612111  14.278309  14.407614 ]\n",
      "Step 50, Loss: [14.74644  14.642204 14.043012 14.370615 14.001321 14.381094 15.03035\n",
      " 14.425363 14.35823  14.792249 14.010915 14.394725 14.112979 14.150549\n",
      " 13.993364 14.565628]\n",
      "Step 60, Loss: [14.484726 14.609362 14.129815 14.383621 14.515284 14.382176 14.313077\n",
      " 14.141102 14.497514 13.922941 14.004421 14.283116 14.133363 14.060224\n",
      " 14.254228 14.53018 ]\n",
      "Step 70, Loss: [14.711308  14.5638075 14.360912  14.346484  14.657297  14.235912\n",
      " 14.372119  14.862883  14.212699  14.569056  14.361495  14.506677\n",
      " 14.580823  14.451703  14.664169  14.389822 ]\n",
      "Step 80, Loss: [14.465041  14.644722  15.188294  14.302066  14.256467  14.065468\n",
      " 14.189507  14.275364  14.347967  14.508522  14.232493  14.6548395\n",
      " 14.545252  14.474857  14.429827  14.035995 ]\n",
      "Step 90, Loss: [14.35624   14.5620985 14.094448  14.414694  14.314681  14.16153\n",
      " 14.255149  14.58819   14.620363  14.273468  14.345161  14.14474\n",
      " 13.921757  14.082431  14.329733  14.322286 ]\n",
      "Step 100, Loss: [14.218518  14.2268095 14.286144  14.651945  14.63968   14.363272\n",
      " 14.204552  14.769244  14.246198  14.381643  14.787827  14.557646\n",
      " 14.240074  13.9297905 13.89763   14.371065 ]\n",
      "Step 110, Loss: [14.485796 14.797547 14.195066 14.428979 14.422873 14.31801  14.254994\n",
      " 14.647835 14.09725  14.880933 14.168175 14.391505 14.470193 14.947771\n",
      " 14.265424 14.879459]\n",
      "Step 120, Loss: [14.403632 14.171336 14.970404 14.510546 14.307677 14.166477 14.318437\n",
      " 14.750211 14.334288 14.319007 14.512725 14.456519 14.282076 14.507889\n",
      " 14.495291 13.990333]\n",
      "Step 130, Loss: [14.357489  14.456893  14.488667  14.5329685 14.334115  13.962883\n",
      " 14.176992  14.572604  14.37661   14.200027  14.363648  14.0001135\n",
      " 14.828421  14.632124  14.40211   14.344913 ]\n",
      "Step 140, Loss: [14.467118  14.417807  14.535758  14.451396  14.14856   14.414128\n",
      " 14.40342   14.697311  14.114477  14.370365  14.414454  14.118915\n",
      " 14.105108  14.6752615 14.563879  14.2325945]\n",
      "Step 150, Loss: [14.271475 14.160111 14.238055 14.328936 14.504589 14.244778 14.225283\n",
      " 14.393813 14.33551  14.038211 14.390393 14.367901 14.12158  14.616013\n",
      " 14.320943 13.953479]\n",
      "Step 160, Loss: [14.376187  14.394297  14.285873  14.787596  14.24882   14.1238985\n",
      " 14.413545  14.373256  14.610201  14.2754345 14.10856   14.304825\n",
      " 14.176836  14.433325  14.549774  14.505727 ]\n",
      "Step 170, Loss: [14.819776  14.200018  14.61233   14.19622   14.392949  14.029228\n",
      " 14.27431   14.164561  14.362407  14.048394  14.261995  14.715559\n",
      " 14.316063  14.3671665 14.090419  14.450319 ]\n",
      "Step 180, Loss: [14.548672  14.565732  14.176568  14.267872  14.206781  14.950606\n",
      " 14.6350565 14.620046  14.346452  14.499664  14.812764  14.437827\n",
      " 14.7159605 14.035818  14.430102  14.181312 ]\n",
      "Step 190, Loss: [14.257513  14.480775  14.700345  14.315379  14.314766  14.414665\n",
      " 14.2057905 14.209336  14.35696   13.988433  14.449568  14.342059\n",
      " 14.430831  14.315663  14.561724  14.234011 ]\n",
      "Step 200, Loss: [14.431225 13.888645 14.805172 14.436481 14.565417 14.713951 14.477011\n",
      " 14.447396 14.187314 14.365805 14.447111 14.633544 14.33538  14.507756\n",
      " 14.923023 14.325561]\n",
      "Step 210, Loss: [14.15447  14.585574 14.402534 14.47134  14.194025 14.139233 14.743862\n",
      " 14.485998 14.559485 14.368674 14.25299  14.318718 14.51263  14.191923\n",
      " 14.59453  14.41899 ]\n",
      "Step 220, Loss: [14.56727   14.839798  14.404816  14.319876  14.738484  14.312672\n",
      " 14.369844  14.201399  14.2161255 14.594471  14.668873  14.321951\n",
      " 14.17639   14.94468   15.090552  14.094562 ]\n",
      "Step 230, Loss: [14.67621   14.296647  14.164541  14.547419  14.470071  14.483887\n",
      " 14.080637  14.498473  14.8654375 14.234019  14.240933  14.389997\n",
      " 14.3806305 14.781775  14.775076  14.593575 ]\n",
      "Step 240, Loss: [14.35913   14.218145  14.51425   14.131596  14.103769  14.571405\n",
      " 13.965614  14.536677  14.393547  14.001254  14.6156845 14.343555\n",
      " 14.4044895 13.991284  14.595072  14.614305 ]\n",
      "Step 250, Loss: [14.57486   14.255011  14.222092  14.709073  14.403521  14.417521\n",
      " 14.023605  14.36197   14.460445  14.1637945 14.197333  14.336924\n",
      " 14.6839075 14.526398  14.437377  14.292906 ]\n",
      "Step 260, Loss: [14.332422  14.180189  14.1120205 14.151888  14.641641  14.49804\n",
      " 13.968262  14.375455  14.445293  14.277291  14.255181  14.616471\n",
      " 14.66386   14.453438  14.675043  15.00837  ]\n",
      "Step 270, Loss: [14.585129 14.339229 14.178209 14.471158 14.85906  14.545587 14.38987\n",
      " 14.292618 14.041211 14.409648 14.535059 14.141012 14.231529 14.082792\n",
      " 14.453502 14.613656]\n",
      "Step 280, Loss: [14.179507  14.207301  14.089885  14.30519   14.337679  14.355375\n",
      " 14.179235  14.406661  14.38561   14.4101925 14.4496765 14.682229\n",
      " 14.172833  14.451963  14.8327    14.597609 ]\n",
      "Step 290, Loss: [14.374315 14.981084 14.403551 14.207614 14.379808 14.247202 14.401918\n",
      " 14.98573  14.364244 14.450407 15.013168 14.316541 14.213083 14.406059\n",
      " 14.590957 14.598423]\n",
      "Step 300, Loss: [14.582778 14.000861 14.41122  14.775891 14.417921 14.131313 14.346536\n",
      " 14.384815 14.253577 14.241091 14.186267 14.356613 14.131809 14.19154\n",
      " 14.31417  14.418587]\n",
      "Step 310, Loss: [14.089086  14.367773  14.262972  14.3299055 14.521947  14.578489\n",
      " 14.481134  14.572269  14.508425  14.735476  14.433442  14.088469\n",
      " 14.3762455 14.889619  14.002275  14.713972 ]\n",
      "Step 320, Loss: [14.136233 14.110105 14.336808 14.254764 14.205009 14.213021 14.013225\n",
      " 14.224989 14.30176  14.310277 14.30293  14.387939 14.82625  14.43096\n",
      " 14.921568 13.985833]\n",
      "Step 330, Loss: [14.4382925 13.879277  14.310004  14.468762  14.051257  14.125351\n",
      " 14.211299  14.369672  14.72756   14.322413  14.504255  14.590148\n",
      " 14.818908  14.315475  14.5884495 14.424634 ]\n",
      "Step 340, Loss: [14.676068  14.306241  14.767773  14.47952   14.439183  14.538889\n",
      " 14.625382  14.366837  14.360304  14.2114105 14.61045   14.516764\n",
      " 14.361203  14.327047  14.241494  14.223429 ]\n",
      "Step 350, Loss: [14.241161  14.146968  14.681991  14.502589  14.430634  14.336501\n",
      " 14.326701  14.207442  14.743866  14.341428  14.313473  14.142945\n",
      " 15.053274  14.476572  14.055031  14.3335705]\n",
      "Step 360, Loss: [14.3946495 14.568403  14.016266  14.143506  14.396546  14.39926\n",
      " 14.40497   14.286075  14.722088  14.58612   14.355872  14.624749\n",
      " 13.972287  14.45036   14.231008  14.539288 ]\n",
      "Step 370, Loss: [14.081672 14.401447 14.531405 14.309029 14.883395 14.322602 14.32266\n",
      " 14.299774 14.147409 14.226399 14.651333 14.200388 14.286075 15.077887\n",
      " 13.910513 14.346277]\n",
      "Step 380, Loss: [14.224524 14.502777 15.11941  14.341341 14.377131 14.18859  14.412803\n",
      " 14.184677 14.475347 14.739018 14.40186  14.149025 14.496966 14.153272\n",
      " 14.377312 14.258404]\n",
      "Step 390, Loss: [14.702684 14.084992 15.007832 14.490617 14.368381 14.632236 14.430056\n",
      " 14.404047 14.574634 14.537448 14.565392 14.278412 14.178948 14.662796\n",
      " 14.65065  14.151197]\n",
      "Epoch 5/10\n",
      "Step 0, Loss: [14.484755  14.278423  14.152657  14.626094  14.268037  13.901334\n",
      " 14.399841  14.496344  14.720066  14.334905  14.289636  14.231781\n",
      " 13.9382515 14.729395  14.201416  14.435936 ]\n",
      "Step 10, Loss: [14.16991  14.258221 14.19259  14.803291 14.412135 14.602236 14.270191\n",
      " 14.305361 14.263856 14.012848 14.48721  14.244103 14.359831 14.344715\n",
      " 14.096103 14.108215]\n",
      "Step 20, Loss: [14.233114 14.276053 14.303853 14.659892 14.748132 14.715572 14.054449\n",
      " 14.428541 14.086263 14.663736 14.8306   14.385391 14.297981 14.366339\n",
      " 14.327346 14.318413]\n",
      "Step 30, Loss: [14.088139 14.409845 14.581273 14.336937 14.359647 14.31599  14.503759\n",
      " 14.540607 14.627234 14.135851 14.592264 14.058055 14.303896 14.218125\n",
      " 14.701748 14.382561]\n",
      "Step 40, Loss: [14.367895  14.789505  14.489761  13.970273  14.496964  14.524904\n",
      " 14.243674  14.867914  14.6528845 14.198824  14.226955  14.257411\n",
      " 14.134871  14.224903  14.549643  14.263931 ]\n",
      "Step 50, Loss: [14.669718 14.318038 14.314647 14.477017 14.630156 14.54055  14.540171\n",
      " 14.187081 14.531783 13.934266 14.480521 14.401662 14.506681 14.461147\n",
      " 14.299091 14.050156]\n",
      "Step 60, Loss: [14.082657 14.364986 14.358906 14.879282 14.535161 14.618447 14.617717\n",
      " 14.591853 14.759598 14.459905 13.944894 14.553545 14.493006 14.092719\n",
      " 14.345771 14.286759]\n",
      "Step 70, Loss: [14.294002  14.13994   14.251472  14.209178  14.090641  14.23635\n",
      " 14.2325115 14.116422  14.762386  14.660956  14.056447  14.095211\n",
      " 14.044267  14.270843  14.114206  14.167427 ]\n",
      "Step 80, Loss: [14.413495  14.277656  14.456505  14.802766  14.21117   14.079348\n",
      " 14.733813  14.417486  14.652475  14.475693  14.690531  14.368828\n",
      " 14.165635  14.3920965 14.221021  14.201886 ]\n",
      "Step 90, Loss: [14.165743 14.318354 14.158134 14.238971 14.770867 14.044315 14.606609\n",
      " 14.968792 14.493289 13.980928 14.435435 14.250009 14.24716  15.062666\n",
      " 14.03281  14.378533]\n",
      "Step 100, Loss: [14.217048 14.385542 14.206874 13.98559  13.967931 14.19336  14.683714\n",
      " 14.262624 14.402511 14.430639 14.785657 14.396342 14.165181 14.460808\n",
      " 14.279029 14.339198]\n",
      "Step 110, Loss: [14.583465  14.6141205 14.417611  13.974726  14.482601  14.356026\n",
      " 14.528635  14.221084  15.103297  14.64553   14.175062  14.317718\n",
      " 14.0084915 14.526519  14.595781  14.509365 ]\n",
      "Step 120, Loss: [13.940182  14.642049  14.597415  14.505302  14.396127  14.610411\n",
      " 14.468882  14.4877205 14.882092  14.364362  14.330235  14.335166\n",
      " 14.403736  14.319273  14.5441065 14.369928 ]\n",
      "Step 130, Loss: [14.504645 14.031716 14.599159 14.137113 14.466679 13.998647 14.142693\n",
      " 14.152904 13.937916 14.271952 14.256084 14.540203 14.557701 14.683736\n",
      " 14.635897 14.296962]\n",
      "Step 140, Loss: [14.4839115 14.2616825 14.342706  14.853756  14.23928   14.464755\n",
      " 14.270462  14.654341  14.466423  14.248234  14.4662    14.596851\n",
      " 14.459615  14.189595  14.428972  14.032698 ]\n",
      "Step 150, Loss: [14.384808  14.486908  14.397947  14.4352665 14.74598   14.567038\n",
      " 14.716735  14.445632  14.350848  14.198732  14.145814  14.566406\n",
      " 14.778808  14.183516  14.381897  14.574108 ]\n",
      "Step 160, Loss: [14.15348  14.211027 14.198119 14.260643 14.828694 14.164676 14.251007\n",
      " 14.494492 14.129155 14.225446 14.352393 14.500928 14.525353 14.319231\n",
      " 14.021548 14.910426]\n",
      "Step 170, Loss: [14.559517  14.95429   14.3833065 14.41997   14.115708  14.089874\n",
      " 14.193609  14.369271  14.444609  14.281594  14.54277   14.388513\n",
      " 14.183374  14.123841  14.574115  14.688891 ]\n",
      "Step 180, Loss: [14.437668 14.281964 14.242759 14.220115 14.456606 14.95099  14.183166\n",
      " 14.888354 14.068865 14.327504 13.992975 14.39581  14.897659 14.352307\n",
      " 14.640326 14.701819]\n",
      "Step 190, Loss: [14.220332  14.771353  14.904247  14.154228  14.359006  14.862899\n",
      " 14.5943575 14.455907  14.40706   14.515829  14.393855  14.0313635\n",
      " 14.296787  14.28603   14.343981  14.666916 ]\n",
      "Step 200, Loss: [14.444308  14.220251  14.441934  14.513263  14.120085  14.235372\n",
      " 14.4160595 14.682628  14.20129   14.57404   14.512139  14.6698475\n",
      " 14.171461  14.556851  14.787824  14.753243 ]\n",
      "Step 210, Loss: [14.600248 14.718205 14.432091 14.345017 14.598894 14.192165 14.068811\n",
      " 14.495791 14.886659 14.271416 14.316427 14.164828 14.004645 14.218895\n",
      " 14.144083 14.684714]\n",
      "Step 220, Loss: [14.362424 14.233994 14.0009   14.233671 14.485754 14.243406 14.361231\n",
      " 14.324652 14.472132 14.47276  14.769049 14.159917 14.514817 14.741456\n",
      " 14.438992 14.033058]\n",
      "Step 230, Loss: [14.561934  14.49532   14.231657  14.187446  14.189452  14.446793\n",
      " 14.3967085 14.641366  14.658609  14.175394  14.536419  14.786478\n",
      " 14.693623  14.258269  14.135136  14.657766 ]\n",
      "Step 240, Loss: [14.780386  14.073659  13.9170685 14.813364  14.187333  14.348058\n",
      " 14.546218  14.233795  14.268068  14.016627  14.578457  14.206098\n",
      " 14.541126  14.367664  14.25292   14.387592 ]\n",
      "Step 250, Loss: [14.485216 14.696818 14.214518 14.849725 14.239278 14.392052 14.044182\n",
      " 14.481552 14.127876 14.359873 14.366848 14.311918 14.001084 14.239081\n",
      " 14.538773 14.778477]\n",
      "Step 260, Loss: [14.644011  14.409815  14.045521  14.722773  14.29772   14.298113\n",
      " 14.438475  14.60582   14.255621  14.383756  14.072233  14.765281\n",
      " 14.2175255 14.548434  14.30145   14.243526 ]\n",
      "Step 270, Loss: [14.412765  14.331133  14.320876  14.641845  14.182535  14.054285\n",
      " 14.163424  14.53049   14.4788685 14.149099  14.596043  14.403172\n",
      " 14.485111  14.610133  14.742253  14.286621 ]\n",
      "Step 280, Loss: [14.614933  14.160832  14.270146  14.288854  14.728081  14.176483\n",
      " 14.115237  14.049373  14.479278  14.546031  14.247037  14.2453375\n",
      " 14.14987   14.161726  14.60185   14.242671 ]\n",
      "Step 290, Loss: [14.097958 14.602079 14.325735 14.712773 14.383548 14.887338 14.99192\n",
      " 14.327871 13.965138 14.498572 14.064378 14.452928 14.377854 14.427074\n",
      " 14.355754 13.990129]\n",
      "Step 300, Loss: [14.870422  14.275844  14.23841   14.384575  14.283434  14.292097\n",
      " 14.2013    14.403058  14.369771  14.736132  14.320633  14.7330065\n",
      " 14.316244  14.05104   14.285695  14.48721  ]\n",
      "Step 310, Loss: [14.240322  14.706893  14.385345  14.3926115 14.282175  14.4696\n",
      " 13.932178  14.241419  14.146147  14.227283  14.251915  14.348707\n",
      " 14.362861  14.047924  14.525758  14.446134 ]\n",
      "Step 320, Loss: [14.254995 14.297928 14.241108 14.410801 14.22611  14.179898 14.164066\n",
      " 14.243829 14.457354 14.30105  14.974776 14.40522  14.238395 14.053069\n",
      " 14.601196 14.314   ]\n",
      "Step 330, Loss: [14.594915 13.90315  14.359251 14.263339 14.439606 14.48992  14.656488\n",
      " 14.698123 14.681105 14.428083 14.569034 14.425114 14.302673 14.118015\n",
      " 14.398787 14.020841]\n",
      "Step 340, Loss: [14.10853   14.566626  14.394543  14.58181   14.593164  14.090178\n",
      " 14.456223  14.251923  14.34286   14.416801  14.089246  14.423662\n",
      " 14.743641  14.4169855 14.275063  14.653543 ]\n",
      "Step 350, Loss: [15.299769  14.517056  14.329021  14.190168  14.038032  14.777673\n",
      " 14.3196125 14.459155  14.666185  14.6082735 14.115117  14.340505\n",
      " 14.432185  14.395988  14.438186  14.477782 ]\n",
      "Step 360, Loss: [14.204695 14.379675 14.331281 14.693079 14.803905 13.956599 14.164316\n",
      " 14.419699 14.472418 14.445162 14.492262 14.190122 14.122667 14.394845\n",
      " 14.604622 14.481409]\n",
      "Step 370, Loss: [14.667559  14.499804  14.449637  14.4198475 14.880578  14.49717\n",
      " 14.885368  14.411763  14.766464  14.34601   14.278247  14.4569025\n",
      " 14.710839  14.655182  14.618931  13.987929 ]\n",
      "Step 380, Loss: [14.476007  14.429177  14.076642  14.230781  14.26884   14.185226\n",
      " 14.361613  14.257026  14.476871  14.3420105 15.003811  14.395973\n",
      " 14.248779  14.433177  14.975471  14.528516 ]\n",
      "Step 390, Loss: [14.237503  14.068249  14.328851  14.064941  14.438221  14.131666\n",
      " 14.295036  14.33296   14.396316  14.697728  14.3046055 13.99129\n",
      " 14.388601  14.309609  14.461829  14.509422 ]\n",
      "Epoch 6/10\n",
      "Step 0, Loss: [14.237157 14.735304 14.662162 14.669457 14.794213 14.012073 14.769318\n",
      " 14.767883 14.970331 14.448231 14.433769 14.279044 14.297252 14.555961\n",
      " 14.926781 14.369391]\n",
      "Step 10, Loss: [14.582306  14.312102  13.921967  14.323357  14.5711775 14.145238\n",
      " 14.467097  14.103327  14.497629  14.346211  14.259795  14.488086\n",
      " 14.518179  14.418439  14.247953  14.372447 ]\n",
      "Step 20, Loss: [14.319814 14.125396 14.153145 14.297681 14.167177 14.113663 14.689083\n",
      " 14.100254 14.055694 14.492685 14.280267 14.242513 14.256323 14.375004\n",
      " 14.351288 14.337292]\n",
      "Step 30, Loss: [14.485086 14.515484 14.286532 14.554608 14.413671 14.281191 14.546053\n",
      " 14.351224 14.536082 14.496014 14.094927 14.751724 14.250804 14.231345\n",
      " 14.740709 14.370176]\n",
      "Step 40, Loss: [14.332096  14.478048  15.032452  14.188011  14.306591  14.453575\n",
      " 14.525382  14.238812  14.1425495 14.449323  14.726024  14.308701\n",
      " 14.291898  14.396297  14.079081  14.38502  ]\n",
      "Step 50, Loss: [14.485553  14.722289  14.736498  14.412683  14.683174  14.452204\n",
      " 14.2291975 14.200171  14.319838  14.63301   14.500243  14.1474\n",
      " 14.615477  14.259791  13.998177  14.801359 ]\n",
      "Step 60, Loss: [14.97465  14.579008 14.327892 14.915881 14.400432 14.595563 14.517236\n",
      " 14.316518 14.305125 14.371656 14.062138 14.182816 14.230962 14.176766\n",
      " 14.517505 14.409256]\n",
      "Step 70, Loss: [14.189647 14.505028 14.230796 14.294053 14.254264 14.423498 14.877991\n",
      " 14.888282 14.396738 14.708196 14.194362 14.502025 14.241833 14.62796\n",
      " 14.701    14.12027 ]\n",
      "Step 80, Loss: [14.012503  14.022706  14.059387  14.595344  14.46322   13.895346\n",
      " 14.280884  14.672719  14.048539  14.2615185 14.209029  14.241489\n",
      " 14.702563  15.064036  14.457451  14.310029 ]\n",
      "Step 90, Loss: [14.288382  14.194517  14.516904  14.4561615 14.519171  14.340713\n",
      " 14.734711  14.858345  14.853811  14.038629  14.569861  14.613562\n",
      " 14.527949  14.299148  14.572171  14.185942 ]\n",
      "Step 100, Loss: [14.290783  14.497773  14.89533   14.346729  14.156058  14.658353\n",
      " 14.349963  14.220645  14.20591   14.1828575 14.608923  14.263282\n",
      " 14.30426   13.946607  14.140461  14.631315 ]\n",
      "Step 110, Loss: [14.269089 14.29283  14.274525 13.96423  14.811626 14.441229 13.980603\n",
      " 14.427674 14.313647 14.276463 14.392616 14.448545 14.495576 14.309076\n",
      " 14.479786 14.306098]\n",
      "Step 120, Loss: [14.769535 14.505605 14.587224 13.99286  14.735387 14.158324 14.626857\n",
      " 14.666111 14.286676 14.303402 14.291936 14.316678 14.267945 13.989741\n",
      " 14.601235 14.559448]\n",
      "Step 130, Loss: [14.169929  14.501057  14.329668  14.215077  14.384032  14.2966385\n",
      " 14.672551  14.337052  14.28193   13.885638  14.147874  14.565061\n",
      " 14.230846  14.393059  14.067307  14.634342 ]\n",
      "Step 140, Loss: [14.258677  14.4156065 14.6081085 14.20774   14.947257  14.720982\n",
      " 14.435393  14.308614  14.207029  14.644492  13.971658  14.451608\n",
      " 14.772057  14.566458  14.451419  14.5206375]\n",
      "Step 150, Loss: [14.438035  14.8819065 14.096757  14.334862  14.151025  13.882826\n",
      " 14.426895  14.751323  14.562686  14.380335  14.296151  14.335841\n",
      " 14.637795  15.001499  14.365302  14.450656 ]\n",
      "Step 160, Loss: [14.359443 15.12731  14.714127 14.281307 14.676436 14.429636 14.45949\n",
      " 14.228834 14.688776 14.217851 14.115771 14.51406  14.392696 14.261905\n",
      " 14.154099 14.063965]\n",
      "Step 170, Loss: [14.548475 14.20119  14.620715 14.440818 14.491157 14.191649 14.461239\n",
      " 14.759557 14.610541 14.261674 14.255886 14.216026 14.146519 14.405709\n",
      " 14.329807 14.534239]\n",
      "Step 180, Loss: [14.192374 14.087304 14.489302 14.402888 14.499296 14.405535 14.209549\n",
      " 15.04727  14.317427 14.183108 14.487225 14.376741 14.565868 14.599486\n",
      " 14.039078 14.16725 ]\n",
      "Step 190, Loss: [14.564949  14.176658  14.685201  14.073319  14.306175  14.656783\n",
      " 14.866679  14.488093  14.270698  14.104926  14.4905615 14.508635\n",
      " 14.4305935 14.981329  14.285803  14.080713 ]\n",
      "Step 200, Loss: [14.551549 14.302811 14.424078 14.571643 14.639374 14.321374 14.361137\n",
      " 14.574024 14.046805 14.275379 14.500223 14.805543 14.556707 14.183948\n",
      " 14.695506 14.413731]\n",
      "Step 210, Loss: [14.094163 14.277829 14.495228 14.381525 13.961283 14.46182  14.561812\n",
      " 14.995383 14.296112 14.587393 14.305291 14.213608 14.251935 14.053272\n",
      " 13.937286 14.285711]\n",
      "Step 220, Loss: [14.418229 14.632572 14.339027 15.147182 14.4047   14.564969 14.420862\n",
      " 14.338087 14.545062 14.540092 14.281959 14.095896 14.478061 14.444948\n",
      " 14.224733 14.336125]\n",
      "Step 230, Loss: [14.172532 14.467489 14.012472 14.452592 14.425917 14.418528 14.033723\n",
      " 14.243819 14.579751 14.417684 14.640435 14.471618 14.326653 14.387082\n",
      " 14.314601 14.084336]\n",
      "Step 240, Loss: [14.411125  14.223934  14.28495   14.608522  14.738812  14.334122\n",
      " 14.11042   14.265617  14.149122  14.599987  14.3402815 14.550335\n",
      " 14.361977  14.544033  14.622714  14.123948 ]\n",
      "Step 250, Loss: [14.390223 14.257887 14.524161 14.404847 14.590341 14.223067 14.134253\n",
      " 14.173124 14.566693 14.063689 14.526864 14.568127 14.517748 14.668932\n",
      " 14.323627 14.381818]\n",
      "Step 260, Loss: [14.9468775 14.173467  14.091319  14.787617  14.280474  14.165653\n",
      " 14.196545  14.393072  14.75825   14.156827  14.417165  14.197691\n",
      " 13.9902    14.45383   14.026928  14.450546 ]\n",
      "Step 270, Loss: [14.386252  14.381909  14.100277  14.108621  14.193188  14.002282\n",
      " 14.316104  14.435527  14.684373  14.486471  14.865719  14.3038645\n",
      " 14.274751  14.388266  14.091065  14.497915 ]\n",
      "Step 280, Loss: [14.231221  15.068182  14.063913  14.62283   14.420901  14.959589\n",
      " 14.190847  14.168567  14.184221  14.485248  14.383075  14.4214525\n",
      " 14.177315  13.907199  13.92703   14.7862   ]\n",
      "Step 290, Loss: [14.29933  14.874141 14.455361 14.437151 14.4872   14.452367 14.686706\n",
      " 14.359625 14.487585 14.264254 14.492735 14.376769 14.303862 14.206019\n",
      " 14.302227 14.393837]\n",
      "Step 300, Loss: [14.577418  14.055074  14.126569  14.298419  14.274753  14.96829\n",
      " 14.369662  14.07925   14.579236  14.120101  13.952549  14.140196\n",
      " 14.1188965 14.263802  14.430455  14.431973 ]\n",
      "Step 310, Loss: [14.731589  14.168744  14.330414  14.434177  14.941713  14.598065\n",
      " 14.282648  14.205734  14.675201  14.4348955 14.101224  14.42949\n",
      " 14.48896   14.21553   14.244774  14.669471 ]\n",
      "Step 320, Loss: [14.446894 14.373642 14.516377 14.415271 14.303585 14.795933 14.901098\n",
      " 14.589793 14.738396 14.055213 14.26162  14.492863 14.531606 14.414136\n",
      " 14.687757 14.429176]\n",
      "Step 330, Loss: [14.257339  14.373919  14.242637  14.528018  14.124332  14.215231\n",
      " 14.02966   14.530035  14.2580595 14.950362  14.339845  14.183762\n",
      " 13.994412  14.043833  14.100175  14.352547 ]\n",
      "Step 340, Loss: [14.423594 14.705996 14.332009 14.621639 14.45408  14.475589 14.378143\n",
      " 14.387329 14.281127 14.43791  14.237544 14.439635 14.340355 14.076642\n",
      " 14.21015  14.298243]\n",
      "Step 350, Loss: [14.16322  14.521344 14.423875 14.324289 14.547681 14.562753 14.453441\n",
      " 14.121933 14.126366 14.287266 14.31388  14.253116 14.347982 14.644949\n",
      " 14.322557 14.119314]\n",
      "Step 360, Loss: [14.491553  14.143851  14.532056  14.491687  14.563232  14.277113\n",
      " 14.272933  14.123543  14.4851055 14.5479765 14.297969  14.319599\n",
      " 14.499779  14.305477  14.342613  14.493752 ]\n",
      "Step 370, Loss: [14.47322   14.507188  14.3369665 14.432103  14.613195  14.623832\n",
      " 14.144186  14.355728  14.660031  14.411393  14.088016  14.310267\n",
      " 14.387156  14.65495   14.182793  14.068867 ]\n",
      "Step 380, Loss: [14.702387  14.220186  14.243468  13.9547825 14.322792  13.989032\n",
      " 14.201399  14.283657  14.3558445 14.241543  14.293811  14.458743\n",
      " 14.412834  14.575432  14.616587  14.430434 ]\n",
      "Step 390, Loss: [14.2666025 14.50986   14.172196  14.234035  14.153289  14.361763\n",
      " 14.467764  14.344259  14.061626  14.172764  14.10379   14.400772\n",
      " 14.685748  14.45441   14.244423  14.462539 ]\n",
      "Epoch 7/10\n",
      "Step 0, Loss: [14.119694 14.383262 14.63104  14.111019 14.553642 14.35613  14.495203\n",
      " 14.34734  14.477905 14.442855 14.755159 14.341686 14.540568 14.616436\n",
      " 14.698682 14.220324]\n",
      "Step 10, Loss: [14.288961  14.357466  14.348455  14.336416  14.189881  13.963695\n",
      " 14.436981  14.310639  14.475289  14.386305  14.324275  14.442009\n",
      " 14.180106  14.5711355 14.141299  14.21103  ]\n",
      "Step 20, Loss: [14.192822  14.28361   14.485612  13.956468  14.442801  14.535028\n",
      " 14.440307  14.404533  14.493111  14.2549515 14.079205  14.076186\n",
      " 14.087161  14.327667  14.263991  14.1679   ]\n",
      "Step 30, Loss: [14.257022  14.598644  14.6356125 14.367739  14.172689  14.42893\n",
      " 14.202735  14.541526  14.183879  14.468936  14.109978  14.447214\n",
      " 14.207425  14.086897  14.7585535 14.0616865]\n",
      "Step 40, Loss: [14.511277  15.032789  14.262893  14.332085  14.391133  13.865657\n",
      " 14.30705   15.134361  14.214388  14.254261  14.471911  14.477375\n",
      " 14.508076  14.369841  14.2660475 14.30151  ]\n",
      "Step 50, Loss: [14.599152 14.491656 14.13508  14.359178 14.335024 14.437304 14.260688\n",
      " 14.50304  14.517541 14.435809 14.164572 14.693346 14.300493 13.910819\n",
      " 14.387756 14.808035]\n",
      "Step 60, Loss: [14.122686  14.111889  14.023131  14.6037655 14.369043  14.324425\n",
      " 14.364228  14.172917  14.366897  14.139015  14.497     14.534785\n",
      " 14.235447  14.277418  14.416512  14.283578 ]\n",
      "Step 70, Loss: [14.3663225 14.524732  14.388199  14.945014  14.072002  14.469265\n",
      " 13.971482  15.030556  14.627922  14.476178  14.295874  14.527096\n",
      " 14.0837555 14.704554  14.743627  14.7236   ]\n",
      "Step 80, Loss: [13.915711  14.450654  14.229645  14.138808  14.572026  14.651978\n",
      " 14.315533  14.128143  14.386467  14.34304   14.128973  14.3881235\n",
      " 14.505896  14.143137  14.261341  14.522829 ]\n",
      "Step 90, Loss: [14.218969  14.093316  14.558672  14.434989  14.472485  14.41128\n",
      " 14.577038  14.451144  14.077723  14.0824175 14.210749  14.676165\n",
      " 14.4603815 14.703878  14.545246  14.817335 ]\n",
      "Step 100, Loss: [14.387991 14.580544 14.634371 14.321064 14.453854 14.375    14.58626\n",
      " 14.102981 13.929208 14.436736 14.652113 14.497054 14.73308  14.298644\n",
      " 14.329577 14.22462 ]\n",
      "Step 110, Loss: [14.431309  14.221208  14.428108  14.196227  14.0336275 14.505842\n",
      " 14.505976  14.185494  14.332104  14.321596  14.286925  14.356581\n",
      " 14.10755   14.581559  14.142759  14.404501 ]\n",
      "Step 120, Loss: [13.933205  14.466871  14.211311  14.109699  14.94904   14.550057\n",
      " 14.448138  14.495473  14.417478  14.50338   14.3497095 14.408357\n",
      " 14.86944   14.359945  14.195633  14.28237  ]\n",
      "Step 130, Loss: [14.28736   14.235694  14.555887  13.932503  14.39864   14.44166\n",
      " 14.60961   14.6293335 14.952076  14.510691  14.608461  14.345362\n",
      " 14.408582  14.382674  14.75771   14.435794 ]\n",
      "Step 140, Loss: [14.458369 14.356496 14.330983 14.285598 14.234098 14.092354 14.408434\n",
      " 14.637644 14.064273 14.38335  14.090569 14.402864 14.443986 14.16782\n",
      " 14.505752 14.891543]\n",
      "Step 150, Loss: [14.414665  14.117959  14.436789  14.578232  14.5823555 14.278404\n",
      " 14.51918   14.206676  14.463661  14.464682  14.666557  14.658246\n",
      " 14.101818  14.628262  14.230818  14.3343115]\n",
      "Step 160, Loss: [14.391476 14.599144 14.320765 14.889125 14.593146 14.93945  14.192022\n",
      " 14.13653  14.162027 14.630608 14.467207 14.297308 14.423401 14.402007\n",
      " 14.024221 14.13528 ]\n",
      "Step 170, Loss: [14.232113  14.4368105 14.299183  14.538583  14.384376  14.424871\n",
      " 14.514077  14.130367  14.454151  14.155754  14.356219  14.6430235\n",
      " 14.34138   14.436647  14.196922  14.162952 ]\n",
      "Step 180, Loss: [14.331087  14.447458  14.299304  14.5724945 14.447354  14.554785\n",
      " 14.517856  14.380909  14.383223  14.3616905 14.009634  14.328037\n",
      " 14.444024  14.276783  14.696026  14.59007  ]\n",
      "Step 190, Loss: [14.314678  14.300144  14.167042  14.333743  14.1094    14.445092\n",
      " 14.498158  14.22447   14.673259  14.433254  14.386437  15.0503\n",
      " 14.3011055 14.039805  14.759287  14.421495 ]\n",
      "Step 200, Loss: [14.547854 14.442761 14.283668 14.189697 13.998994 14.456489 14.381047\n",
      " 14.203324 14.118111 14.994453 14.955479 14.370543 14.387684 14.332808\n",
      " 13.962836 14.21474 ]\n",
      "Step 210, Loss: [14.37793   14.3235035 14.501456  14.035941  14.140711  14.08992\n",
      " 14.360097  14.133209  14.154842  14.505505  14.210053  14.624225\n",
      " 14.09338   14.284576  14.108829  14.194082 ]\n",
      "Step 220, Loss: [14.097533  14.560148  14.4630375 14.17469   14.427655  14.452704\n",
      " 14.811774  14.166931  14.375937  14.462677  13.98184   14.280334\n",
      " 14.664105  14.031355  13.949553  14.311286 ]\n",
      "Step 230, Loss: [14.154649  14.512328  14.092241  14.675685  14.381673  14.03675\n",
      " 14.306     14.181069  13.977499  14.5082035 14.396026  14.566007\n",
      " 14.450282  14.721661  14.114323  14.382476 ]\n",
      "Step 240, Loss: [14.8368435 14.181322  14.189573  14.323668  14.531896  14.214314\n",
      " 15.036575  14.209629  14.540155  14.300808  14.3248005 14.398051\n",
      " 14.407049  14.595611  14.50495   14.159941 ]\n",
      "Step 250, Loss: [14.608573 14.306962 14.44155  14.589156 14.761102 14.577039 14.443378\n",
      " 14.468447 14.690736 14.308781 14.066242 14.397034 14.571106 14.703111\n",
      " 14.512868 14.611695]\n",
      "Step 260, Loss: [14.505934 14.550095 14.456205 14.847516 14.423272 14.425162 14.129072\n",
      " 14.418175 14.04347  14.199847 14.205753 14.344868 14.553121 14.356045\n",
      " 14.43601  14.919991]\n",
      "Step 270, Loss: [14.327405  14.064973  14.501773  14.123505  14.2484865 14.440922\n",
      " 14.568039  14.33061   13.989297  13.9841175 14.212128  14.284385\n",
      " 14.30876   14.138316  14.566254  14.139962 ]\n",
      "Step 280, Loss: [14.156089  14.0753975 14.644735  14.23128   14.401156  14.251948\n",
      " 14.540244  14.018656  14.396279  14.406565  14.561545  14.238835\n",
      " 14.528775  14.416201  14.608327  15.094291 ]\n",
      "Step 290, Loss: [14.176871  14.251365  14.214094  14.478733  14.160258  14.393787\n",
      " 13.889478  14.7090645 14.111685  14.805586  14.982268  14.329152\n",
      " 14.237154  14.304651  14.077756  14.929517 ]\n",
      "Step 300, Loss: [14.166371  14.217784  14.603622  14.451216  14.383348  14.57513\n",
      " 14.419202  14.642094  13.956254  14.155102  14.486625  14.27803\n",
      " 14.383498  14.395946  14.6643715 14.247854 ]\n",
      "Step 310, Loss: [14.454578  14.495423  14.372879  14.252273  14.208594  14.341319\n",
      " 14.701231  14.201029  13.946746  14.2688055 14.571813  14.199271\n",
      " 14.426566  14.672175  14.570521  14.523318 ]\n",
      "Step 320, Loss: [14.511244  14.083068  14.645233  14.802749  13.974373  14.1323395\n",
      " 14.290717  14.2566185 14.725439  14.683462  14.747773  14.433257\n",
      " 14.004851  14.570907  14.312984  14.719121 ]\n",
      "Step 330, Loss: [14.562651 14.263182 14.852104 14.134584 14.30953  13.947844 14.547936\n",
      " 14.210768 14.328154 14.734431 14.170986 14.544686 14.307871 14.553467\n",
      " 14.532646 14.13458 ]\n",
      "Step 340, Loss: [14.500554 14.659103 14.538445 14.563438 14.407323 14.825172 14.488095\n",
      " 14.120555 14.272689 14.13602  14.18117  14.44088  13.95779  14.505746\n",
      " 14.278376 14.105705]\n",
      "Step 350, Loss: [14.524113 14.291176 14.629775 14.418928 14.53657  14.25415  14.346355\n",
      " 14.513266 14.310383 14.303406 14.871049 14.276849 14.558637 14.570189\n",
      " 14.234144 14.419279]\n",
      "Step 360, Loss: [14.338236 14.205362 14.170864 14.267539 14.511533 14.479198 14.468627\n",
      " 14.180872 14.011119 14.191002 14.674656 14.258153 14.632506 14.273115\n",
      " 14.510273 14.1715  ]\n",
      "Step 370, Loss: [14.401814  14.58988   14.7468195 14.476266  14.3986635 14.500462\n",
      " 14.615501  14.1926365 14.221797  14.166924  14.417659  14.10686\n",
      " 14.725013  14.319707  14.320066  14.162152 ]\n",
      "Step 380, Loss: [14.417365  14.8439865 14.547441  14.674377  14.459821  14.663135\n",
      " 14.177284  14.43261   14.2636385 14.188818  14.575275  14.337257\n",
      " 14.4966135 14.9232025 14.238361  14.690398 ]\n",
      "Step 390, Loss: [14.101643  14.131704  14.183293  14.776024  14.406064  14.1517105\n",
      " 14.232014  14.224575  14.451484  14.220116  14.289421  14.40807\n",
      " 14.313635  14.176253  14.377054  14.32556  ]\n",
      "Epoch 8/10\n",
      "Step 0, Loss: [14.217326 14.101424 14.280624 14.237269 14.579811 14.690002 14.10988\n",
      " 14.295322 14.418832 14.425641 14.005432 13.926186 14.878068 14.307708\n",
      " 14.32237  14.651474]\n",
      "Step 10, Loss: [14.490181  14.364545  14.058732  14.7171955 14.181266  14.299657\n",
      " 14.426625  14.547761  14.242967  14.31617   14.2497225 14.3812475\n",
      " 14.585594  14.521189  14.10042   14.3702345]\n",
      "Step 20, Loss: [14.636618  14.268493  14.055065  14.363662  14.561231  14.470156\n",
      " 14.295529  14.222313  14.725394  14.221778  14.516556  14.524101\n",
      " 15.121094  14.2314825 14.182368  14.413286 ]\n",
      "Step 30, Loss: [13.994724 14.409046 14.490957 14.240701 14.320983 14.292419 14.455733\n",
      " 14.437836 14.517814 14.877264 14.296008 14.294348 14.146374 14.150135\n",
      " 14.419167 14.382661]\n",
      "Step 40, Loss: [14.55385  14.635378 14.679913 14.485544 14.540715 14.285962 13.998224\n",
      " 14.487657 14.52695  14.435688 14.384968 14.415956 14.488546 14.412185\n",
      " 14.41665  14.409848]\n",
      "Step 50, Loss: [14.461704  14.6465845 14.367338  14.748265  14.575161  14.485449\n",
      " 14.214934  14.013716  14.214331  14.606662  14.464357  14.357982\n",
      " 14.171901  14.601069  14.3810215 14.05097  ]\n",
      "Step 60, Loss: [14.451412  14.42916   14.444358  14.615763  14.196998  14.303736\n",
      " 14.33921   14.27594   14.1086445 14.774099  14.565417  14.55131\n",
      " 14.262389  14.558435  13.9167795 14.260647 ]\n",
      "Step 70, Loss: [14.193371  15.109272  14.5674095 14.4234085 14.655131  14.4608755\n",
      " 14.045666  13.95832   14.1773    14.7533245 14.412432  14.672732\n",
      " 14.334023  14.38014   14.300793  14.284042 ]\n",
      "Step 80, Loss: [14.223224  14.219728  14.442872  14.279733  14.57093   14.552138\n",
      " 14.269391  14.488296  14.619829  14.350891  14.36578   14.219924\n",
      " 14.338332  14.410465  14.5043545 14.287636 ]\n",
      "Step 90, Loss: [14.517346  14.748446  14.50313   14.305799  14.349287  14.115596\n",
      " 14.763921  14.321185  14.317741  14.295178  14.407896  14.604036\n",
      " 14.2227745 14.758061  14.089996  14.742344 ]\n",
      "Step 100, Loss: [13.943404 14.291872 14.260604 14.446788 14.327253 14.219203 14.474141\n",
      " 14.201598 14.604628 14.716421 13.918363 14.436047 14.569025 14.169467\n",
      " 14.020782 14.39981 ]\n",
      "Step 110, Loss: [15.0807705 14.352697  14.288522  14.134054  14.527943  14.234156\n",
      " 14.352565  14.275291  14.134978  14.292609  14.404311  14.369798\n",
      " 14.425551  14.099539  14.2417555 14.3065195]\n",
      "Step 120, Loss: [14.262918 14.200332 14.418591 15.004942 14.167239 14.637087 14.353205\n",
      " 14.345411 14.71362  14.10512  14.352954 14.312984 14.347701 14.520908\n",
      " 14.422093 14.916234]\n",
      "Step 130, Loss: [14.442344  14.848545  14.570372  14.042354  14.286003  13.928851\n",
      " 14.530737  14.381872  14.011934  14.686557  14.5701685 14.447687\n",
      " 14.327777  14.124105  14.194791  14.752416 ]\n",
      "Step 140, Loss: [14.180649  14.138693  14.751266  14.416264  14.442504  14.8266\n",
      " 14.375271  14.1362505 14.5749855 14.49738   14.011641  14.820768\n",
      " 14.278533  14.554438  14.424574  14.487692 ]\n",
      "Step 150, Loss: [14.405105 15.061329 14.193484 14.633057 14.334204 14.162768 14.095397\n",
      " 15.170796 14.425978 14.296914 14.438017 14.442335 14.37004  14.389208\n",
      " 14.565358 14.597495]\n",
      "Step 160, Loss: [14.199931  13.918443  14.499112  14.055332  14.645641  14.0500965\n",
      " 14.556732  14.404889  14.1540365 14.285309  14.506086  14.256738\n",
      " 14.298874  14.423622  14.413675  14.740771 ]\n",
      "Step 170, Loss: [14.261648 14.613534 14.591918 14.468775 14.323377 13.951465 14.364277\n",
      " 14.23711  14.224409 14.370221 14.333541 14.107407 14.14187  14.366928\n",
      " 14.614301 14.013895]\n",
      "Step 180, Loss: [14.260036  14.40123   14.45467   14.398528  14.292296  14.50153\n",
      " 13.981241  14.311094  14.280212  14.69829   14.165415  14.322807\n",
      " 14.1117115 14.517734  14.436874  14.36465  ]\n",
      "Step 190, Loss: [14.823187 14.162441 14.332401 14.586298 14.514019 14.385739 14.294257\n",
      " 13.897888 14.476902 14.123998 14.515563 14.572382 14.320422 14.170862\n",
      " 14.129538 14.439303]\n",
      "Step 200, Loss: [14.720082 14.449471 14.192818 14.876142 14.688009 14.669483 14.632986\n",
      " 14.364603 14.096895 14.336862 14.435187 14.394944 14.372085 14.378321\n",
      " 14.492155 14.609527]\n",
      "Step 210, Loss: [14.72682   14.392734  14.238658  14.0865965 14.30648   14.243622\n",
      " 13.928737  14.410605  14.181453  14.476031  14.300421  14.427747\n",
      " 14.013383  14.420327  14.431936  14.106586 ]\n",
      "Step 220, Loss: [14.282212  14.308967  14.384821  14.210085  14.438643  14.839996\n",
      " 14.269993  14.228822  14.051783  14.2178135 14.182633  14.362637\n",
      " 14.257802  14.113011  14.378651  14.106672 ]\n",
      "Step 230, Loss: [14.106075 14.047304 14.8112   14.226876 14.313345 14.485648 14.581537\n",
      " 14.358939 14.64882  14.237906 14.25076  14.675574 14.38468  14.196266\n",
      " 14.210676 14.244057]\n",
      "Step 240, Loss: [14.144159  14.175272  14.4858265 14.167019  14.138399  14.598778\n",
      " 14.50197   14.248399  14.451976  14.3058    14.300628  14.440563\n",
      " 14.316937  14.292327  14.307928  14.269082 ]\n",
      "Step 250, Loss: [14.268793  14.566151  14.7138405 14.609475  14.284679  14.082515\n",
      " 14.2128105 14.520339  14.216305  14.263208  14.504074  14.515521\n",
      " 14.225361  14.368434  14.491013  14.285997 ]\n",
      "Step 260, Loss: [14.401616 14.259435 14.40198  14.497217 14.367741 14.029229 14.311658\n",
      " 14.341399 14.874265 14.33455  14.399547 14.623397 14.60339  14.289953\n",
      " 14.519619 14.144359]\n",
      "Step 270, Loss: [14.187611  14.148671  14.2626095 14.163071  14.471668  14.488308\n",
      " 14.292586  14.059451  14.361935  14.028826  14.446019  14.303142\n",
      " 14.31283   14.316747  14.432436  13.954156 ]\n",
      "Step 280, Loss: [14.254263 14.26327  14.401426 14.414303 14.219637 14.575696 14.713639\n",
      " 14.462689 14.363151 14.394517 14.496135 14.56267  14.141495 13.965671\n",
      " 14.258689 14.452028]\n",
      "Step 290, Loss: [14.639768  14.177608  14.671948  14.532678  14.159888  14.393106\n",
      " 14.263431  14.21964   14.758892  14.334058  14.11776   14.62843\n",
      " 14.2606735 14.55319   14.562591  14.411229 ]\n",
      "Step 300, Loss: [14.822689  14.283873  14.232339  14.344526  14.374322  14.194828\n",
      " 14.4322815 14.831094  14.901688  14.209005  14.331873  13.975227\n",
      " 14.646893  14.295121  14.427937  14.180905 ]\n",
      "Step 310, Loss: [14.513366  13.918077  14.3691225 14.3748865 14.404822  14.276184\n",
      " 14.236004  14.406029  14.453415  14.01719   14.526853  14.399413\n",
      " 14.52355   14.542458  14.13987   14.20457  ]\n",
      "Step 320, Loss: [14.437679 14.560858 14.792183 14.35861  14.725922 14.392693 14.236757\n",
      " 14.273396 14.289668 14.094679 14.393618 14.287369 14.688773 14.518161\n",
      " 14.604888 14.379054]\n",
      "Step 330, Loss: [14.382203 14.594523 14.936233 14.45507  14.395961 14.371082 14.281085\n",
      " 14.74608  14.620246 14.576956 14.682301 14.384348 14.719767 14.631938\n",
      " 14.024259 14.698858]\n",
      "Step 340, Loss: [14.422268 14.145697 14.101928 14.993536 14.119038 14.379128 14.305603\n",
      " 14.497606 14.08055  14.612895 14.348875 14.430588 14.479156 14.875551\n",
      " 14.021582 14.446383]\n",
      "Step 350, Loss: [14.357294 14.499178 14.328299 14.281239 14.242395 14.374827 14.247012\n",
      " 14.224991 14.375175 14.416869 14.367266 14.230792 14.508308 14.621523\n",
      " 14.157783 14.347788]\n",
      "Step 360, Loss: [14.223857  14.510004  14.300875  14.3053255 14.037621  14.5284\n",
      " 14.723939  14.138855  14.377482  14.334859  14.58014   14.59337\n",
      " 14.545012  14.9908905 14.387733  14.436684 ]\n",
      "Step 370, Loss: [14.356503  14.372079  15.017449  13.988154  14.823087  14.381657\n",
      " 14.404624  14.053887  14.390848  14.549978  14.723787  14.306579\n",
      " 14.6792965 14.230931  14.17035   14.228405 ]\n",
      "Step 380, Loss: [14.518671  14.437515  14.270953  14.516477  15.126013  14.307747\n",
      " 14.146244  14.180811  14.971677  14.661792  14.360399  14.0618725\n",
      " 14.303591  14.478602  14.475601  14.1435995]\n",
      "Step 390, Loss: [14.284917  14.251946  14.280655  14.066497  14.227494  14.219783\n",
      " 14.424094  14.2494335 14.023542  14.5900135 14.433663  14.685225\n",
      " 14.127752  14.406187  14.484612  14.785914 ]\n",
      "Epoch 9/10\n",
      "Step 0, Loss: [14.370668 14.218889 14.34458  14.243326 14.519394 14.662085 14.772498\n",
      " 14.418783 14.016089 14.392842 14.417969 14.41256  14.379172 14.325915\n",
      " 14.231344 14.613819]\n",
      "Step 10, Loss: [14.1607485 14.523661  14.161146  14.335422  14.232083  14.393881\n",
      " 14.597601  14.2337265 14.497841  14.453439  14.39445   14.768789\n",
      " 14.120081  14.352916  14.3218    14.251049 ]\n",
      "Step 20, Loss: [14.384549  14.4704    14.559018  14.618206  14.0724745 14.65272\n",
      " 14.039307  14.840436  13.878885  14.416775  14.6064005 15.136542\n",
      " 14.883114  14.382847  14.514942  14.463641 ]\n",
      "Step 30, Loss: [14.606612 14.19355  14.388941 14.589312 14.447178 14.218319 14.142423\n",
      " 14.271715 14.635133 15.040917 14.619945 14.702458 14.380182 14.280135\n",
      " 14.57796  14.379497]\n",
      "Step 40, Loss: [14.144258 14.484658 14.225431 14.408375 14.40762  14.149654 14.120225\n",
      " 14.034264 14.323554 14.041291 14.175861 14.28322  14.727307 14.457009\n",
      " 14.638632 14.219976]\n",
      "Step 50, Loss: [14.565011  14.356312  14.487334  14.4508505 14.250938  14.279333\n",
      " 14.20898   14.366171  14.581638  14.533227  14.115971  14.1998415\n",
      " 14.477376  13.975932  14.474751  14.266544 ]\n",
      "Step 60, Loss: [14.643011 14.169146 14.56863  14.588975 14.316117 14.275545 14.447047\n",
      " 14.463431 14.932986 14.471619 14.209262 14.233866 14.588439 14.540036\n",
      " 14.059352 14.005708]\n",
      "Step 70, Loss: [14.275763  14.293011  14.144198  14.662438  14.2776165 14.766894\n",
      " 14.226135  14.37267   14.66169   14.79636   14.328947  14.294347\n",
      " 14.298649  14.948861  14.505172  14.245535 ]\n",
      "Step 80, Loss: [14.075521 14.4312   14.119966 14.320361 14.213186 14.360712 14.086062\n",
      " 14.570754 14.043603 14.304241 14.321637 14.41     14.71019  14.065622\n",
      " 14.203974 14.131234]\n",
      "Step 90, Loss: [14.472893  14.349149  14.830343  14.714844  14.4798765 14.302291\n",
      " 14.220533  14.130001  14.090107  14.641181  14.411682  14.746507\n",
      " 14.515893  14.859716  14.408372  14.309894 ]\n",
      "Step 100, Loss: [14.6394825 14.222707  14.293657  14.885055  14.22611   14.634239\n",
      " 14.374823  14.652254  14.222602  14.716611  14.355465  14.571729\n",
      " 13.949103  14.2661915 14.663212  14.58697  ]\n",
      "Step 110, Loss: [14.262593 14.09048  14.227424 14.863529 14.364729 14.262547 14.96844\n",
      " 14.198989 14.138844 14.749775 14.425429 14.291677 14.447955 14.230527\n",
      " 14.768766 14.331114]\n",
      "Step 120, Loss: [14.578642 14.088697 14.885252 14.742172 14.14545  14.361083 14.008684\n",
      " 14.436419 14.262677 14.52775  14.200928 14.203836 14.62063  14.002043\n",
      " 14.23409  14.310621]\n",
      "Step 130, Loss: [14.2171335 14.466583  14.524327  14.460135  14.502673  14.445392\n",
      " 14.2498255 14.441345  14.496995  14.388513  14.246578  14.162896\n",
      " 14.587656  14.428544  15.144794  14.13052  ]\n",
      "Step 140, Loss: [14.464212  14.2927    14.176477  14.225098  14.219814  14.682215\n",
      " 14.116664  14.425935  14.610533  14.445201  14.382793  14.688599\n",
      " 14.2629385 14.138785  14.242979  14.206253 ]\n",
      "Step 150, Loss: [14.923621  14.424354  14.376915  14.459412  14.7255745 14.28255\n",
      " 14.357399  14.533523  14.461285  14.334384  14.062414  14.462376\n",
      " 14.08071   14.528371  14.216507  14.62479  ]\n",
      "Step 160, Loss: [14.400335  14.28348   14.302558  14.350041  14.433278  14.437447\n",
      " 13.921273  14.220755  14.210685  14.301989  14.60704   14.420208\n",
      " 14.2981    14.230598  14.476868  14.4706545]\n",
      "Step 170, Loss: [14.537192  14.1724615 14.26409   14.311232  14.31161   14.217703\n",
      " 14.071796  14.461251  14.305877  14.837278  14.200891  14.318647\n",
      " 14.342209  14.14103   14.420563  14.683148 ]\n",
      "Step 180, Loss: [14.360221 14.389901 14.605806 14.651746 14.260135 14.582751 14.627667\n",
      " 15.143294 14.199213 14.212105 14.635235 14.381466 14.300453 14.481583\n",
      " 14.545899 14.514718]\n",
      "Step 190, Loss: [14.290522  14.300463  14.446071  14.06986   13.889727  14.792459\n",
      " 14.078233  14.872988  14.2409115 14.69449   14.191636  14.027462\n",
      " 14.875763  14.225437  14.193955  14.567319 ]\n",
      "Step 200, Loss: [14.247903 14.874239 14.192124 14.603303 14.529507 14.474598 14.011361\n",
      " 14.555951 14.303315 14.249771 14.455347 14.679562 13.945651 14.132784\n",
      " 14.230592 14.315401]\n",
      "Step 210, Loss: [14.42891  14.174764 15.109513 14.219968 14.176811 14.473347 14.406297\n",
      " 14.247693 14.212477 14.474638 14.210225 14.364157 14.43309  14.372452\n",
      " 13.997965 14.407286]\n",
      "Step 220, Loss: [14.45664  14.466713 14.161545 14.431809 14.391155 14.24403  14.345311\n",
      " 14.538743 14.654271 14.624143 14.404571 14.446351 14.145999 14.296654\n",
      " 14.218793 14.330942]\n",
      "Step 230, Loss: [14.703738 14.719872 14.225732 14.07729  14.449476 14.646327 14.385645\n",
      " 14.301846 14.041967 14.328119 14.461293 14.291704 14.382893 14.400854\n",
      " 14.446426 14.292458]\n",
      "Step 240, Loss: [14.405662  14.093723  14.21046   14.2414665 14.435262  14.108193\n",
      " 14.6024685 14.134871  14.117636  14.327773  14.041531  14.512188\n",
      " 13.987543  14.314671  14.153406  14.584549 ]\n",
      "Step 250, Loss: [14.677966  14.633513  14.104399  14.218071  14.573651  14.738991\n",
      " 14.180342  14.145418  14.2517395 14.392311  14.441072  14.395737\n",
      " 14.307867  14.56477   14.209537  13.995598 ]\n",
      "Step 260, Loss: [14.336077  14.438852  14.47494   14.547843  13.900893  14.235365\n",
      " 14.308358  14.302762  14.337941  14.476393  14.782359  14.469302\n",
      " 14.429839  14.5691395 14.299764  14.561779 ]\n",
      "Step 270, Loss: [14.298033  14.141409  14.665486  14.290211  14.446918  14.553863\n",
      " 14.5425825 14.51531   14.399072  14.527783  14.710854  14.556776\n",
      " 14.513854  14.1533785 13.960835  14.1116085]\n",
      "Step 280, Loss: [14.561948  14.272206  14.650816  14.541754  14.31733   14.564801\n",
      " 14.204956  14.36692   14.777339  14.384432  14.411559  14.241137\n",
      " 14.1930485 14.172071  14.350081  14.227225 ]\n",
      "Step 290, Loss: [14.396457 14.202876 14.297117 14.254503 14.464362 14.264922 14.672482\n",
      " 14.362326 14.337413 14.903264 14.457343 14.125229 14.305671 14.232399\n",
      " 14.124342 14.452493]\n",
      "Step 300, Loss: [14.407872  14.421912  14.237613  14.610504  14.908874  14.455832\n",
      " 14.725955  14.422409  14.3460245 14.489653  14.130331  14.197443\n",
      " 14.363008  14.270049  14.47095   14.566054 ]\n",
      "Step 310, Loss: [14.469896  14.638702  13.970314  14.342464  14.3046055 14.728835\n",
      " 14.52431   14.408028  14.75756   14.326612  14.411938  14.089316\n",
      " 14.177057  14.445639  13.989036  14.592258 ]\n",
      "Step 320, Loss: [14.375233  14.280967  14.608516  14.58416   14.763059  14.566436\n",
      " 14.124331  14.46012   14.599128  14.595163  14.128488  14.2334385\n",
      " 14.420513  14.341835  14.5875    14.407605 ]\n",
      "Step 330, Loss: [14.513103 14.330879 14.493195 14.103377 14.219517 14.127249 14.209051\n",
      " 14.375556 14.293494 14.382044 14.681245 14.299264 14.109975 14.323251\n",
      " 14.302074 14.533693]\n",
      "Step 340, Loss: [14.276141 14.100075 14.333036 14.436606 14.497558 14.311318 14.07088\n",
      " 14.087656 14.284554 14.429833 13.967508 14.840133 14.427074 14.178678\n",
      " 14.342424 14.000369]\n",
      "Step 350, Loss: [14.129254 13.908668 14.393927 14.39062  14.548191 14.582846 14.382351\n",
      " 14.437074 14.65419  14.196177 14.432    14.486808 14.105227 14.152889\n",
      " 14.328428 13.990583]\n",
      "Step 360, Loss: [14.365674 14.300468 14.795449 14.57959  14.259589 14.61558  14.367228\n",
      " 14.18779  13.966016 14.680261 14.466724 14.455685 14.437745 14.490181\n",
      " 14.007379 14.285765]\n",
      "Step 370, Loss: [14.272937 14.047489 14.058346 14.259371 14.02333  14.836701 14.26727\n",
      " 14.122451 14.484517 14.309902 14.102768 14.175022 14.249813 14.655818\n",
      " 14.73516  14.294343]\n",
      "Step 380, Loss: [14.124747 14.434619 14.33583  14.669147 14.521094 14.557182 14.316196\n",
      " 14.36956  14.494827 14.562556 14.442333 14.168724 14.237083 14.653252\n",
      " 14.262967 14.428762]\n",
      "Step 390, Loss: [14.380083  14.315296  14.187821  14.042369  14.521987  14.262617\n",
      " 14.356272  14.471582  14.342415  14.103388  14.503711  14.116051\n",
      " 14.0196705 14.531469  14.25113   14.196516 ]\n",
      "Epoch 10/10\n",
      "Step 0, Loss: [14.30062  14.456616 14.384826 14.687581 14.287771 14.112967 14.373045\n",
      " 14.338994 14.042115 14.478214 14.787629 14.52815  14.53849  14.175255\n",
      " 14.032878 14.597223]\n",
      "Step 10, Loss: [14.564862  14.576629  14.3604355 14.394968  14.328549  14.312772\n",
      " 14.614795  14.083721  14.32408   14.664788  14.036572  14.26852\n",
      " 14.136753  14.441061  14.0914955 14.231601 ]\n",
      "Step 20, Loss: [14.212762  14.656109  14.270496  14.200681  14.68299   15.171717\n",
      " 14.438114  14.412579  14.17758   14.382422  14.676161  14.132602\n",
      " 14.38837   14.2476635 14.353116  14.53541  ]\n",
      "Step 30, Loss: [14.33367   13.98955   14.506792  14.132007  14.774218  14.233489\n",
      " 14.431733  14.186478  14.419704  14.358221  14.325087  14.080228\n",
      " 14.563467  14.727335  14.561834  14.2396555]\n",
      "Step 40, Loss: [14.835603  14.8730545 14.197964  14.335021  14.354781  14.210483\n",
      " 14.152351  14.543942  14.199903  13.898566  14.398646  14.258806\n",
      " 14.376921  14.016647  14.299058  14.624645 ]\n",
      "Step 50, Loss: [14.203864  14.347457  14.409695  14.559922  14.5257845 14.664265\n",
      " 14.523873  15.017071  14.009362  14.229103  14.3351    13.930257\n",
      " 14.514108  14.443474  14.5451975 14.294171 ]\n",
      "Step 60, Loss: [14.260686  14.795261  14.462107  14.247181  14.396447  14.354002\n",
      " 14.781067  14.340777  14.508018  14.276722  14.065609  14.325781\n",
      " 14.1764145 14.422407  14.505524  14.750866 ]\n",
      "Step 70, Loss: [14.240787 14.442338 14.459938 14.217924 14.121445 14.20737  14.669112\n",
      " 14.272644 14.259716 14.518973 14.547401 14.384051 14.296151 14.354329\n",
      " 14.398933 14.180681]\n",
      "Step 80, Loss: [14.449665  14.267782  14.771488  14.255716  14.394375  14.747102\n",
      " 14.147457  14.142725  14.604507  14.630706  14.305285  14.7666445\n",
      " 14.368683  14.420658  14.58605   14.52149  ]\n",
      "Step 90, Loss: [14.002588 14.538262 14.728563 14.690649 14.23999  14.556914 14.379585\n",
      " 14.41244  14.797828 14.548391 14.394421 14.381537 14.462421 14.317528\n",
      " 14.155334 14.47448 ]\n",
      "Step 100, Loss: [14.063866 14.479506 14.244419 14.313196 14.645569 14.403837 14.243026\n",
      " 14.327612 14.352461 14.616347 14.287372 14.459116 14.148435 14.167164\n",
      " 14.132133 14.341243]\n",
      "Step 110, Loss: [14.066668 14.115119 14.182474 14.307623 14.396636 14.211654 14.535292\n",
      " 14.442015 14.752931 14.280637 14.267261 14.973028 14.385244 14.621553\n",
      " 14.185329 14.490179]\n",
      "Step 120, Loss: [14.080106 14.126496 14.352102 14.343174 14.485684 14.703125 14.083016\n",
      " 14.46006  14.092053 14.17732  14.478001 14.246511 14.438336 14.558632\n",
      " 15.022384 14.5023  ]\n",
      "Step 130, Loss: [14.138201 14.020247 14.471443 14.440551 14.285434 14.701931 14.747059\n",
      " 14.298711 13.949392 14.053983 14.221994 15.055993 14.189321 14.670092\n",
      " 13.94471  14.100717]\n",
      "Step 140, Loss: [14.339297  14.787687  14.445307  14.292934  14.3365755 14.327141\n",
      " 14.31195   14.557497  14.126438  14.714368  14.475081  14.282419\n",
      " 14.081371  14.257842  14.016664  14.08101  ]\n",
      "Step 150, Loss: [14.571685 14.597884 14.487268 14.249703 14.355695 14.815166 14.13798\n",
      " 14.439317 14.238367 14.000115 14.534293 14.238023 14.069719 14.646069\n",
      " 14.684683 13.950374]\n",
      "Step 160, Loss: [14.498736 14.419531 14.444124 14.32325  14.170105 14.467767 14.285649\n",
      " 14.212495 14.331593 14.011361 14.386559 14.745247 14.357585 14.767637\n",
      " 14.440975 14.324326]\n",
      "Step 170, Loss: [14.260853  14.228039  14.240017  14.9332695 14.451782  14.362719\n",
      " 14.311775  14.3011675 14.368209  14.471187  14.4765415 14.5784\n",
      " 14.377942  14.716746  14.231713  14.736559 ]\n",
      "Step 180, Loss: [14.404723 13.980517 14.412534 14.458054 14.306783 14.479578 14.352579\n",
      " 14.102551 14.468793 14.404446 14.078324 14.298777 14.539665 14.149982\n",
      " 14.271576 14.379701]\n",
      "Step 190, Loss: [14.3260145 14.634579  14.8041725 14.295574  14.729587  13.939817\n",
      " 14.594872  14.420435  14.392037  14.4093895 14.459221  14.606403\n",
      " 14.281142  14.316024  14.008883  14.377917 ]\n",
      "Step 200, Loss: [14.241244 14.430286 14.370534 14.546513 14.212881 14.338572 14.196455\n",
      " 14.44822  14.480196 13.918155 14.273072 14.464602 14.28445  14.151615\n",
      " 14.354054 14.526316]\n",
      "Step 210, Loss: [14.707151  14.526206  14.625774  14.135782  14.456841  14.203956\n",
      " 14.290629  14.155653  14.174315  14.503019  14.1115675 14.72544\n",
      " 14.090611  14.344058  14.272371  14.598223 ]\n",
      "Step 220, Loss: [14.388788 14.075808 14.285489 14.429855 14.418551 14.481209 14.2991\n",
      " 14.216301 14.095587 14.55439  14.119957 14.319932 14.478704 14.4541\n",
      " 14.033653 14.135732]\n",
      "Step 230, Loss: [13.941585 14.647915 14.463511 14.214596 14.498762 14.510445 14.310875\n",
      " 14.965761 14.089588 14.312484 14.611165 14.606378 14.806623 14.54196\n",
      " 14.38361  14.307266]\n",
      "Step 240, Loss: [14.103429  15.068069  14.482743  14.727704  14.264983  13.941659\n",
      " 14.196189  14.4442835 14.404677  14.466743  14.097692  14.203078\n",
      " 14.517507  14.178454  14.290318  14.4893055]\n",
      "Step 250, Loss: [14.53557  14.183791 14.379313 14.337466 14.679005 14.709228 14.600719\n",
      " 14.44269  14.509666 14.573826 14.197584 14.982479 14.53057  14.556622\n",
      " 14.455933 14.154474]\n",
      "Step 260, Loss: [14.537699  14.649284  14.414508  14.6430645 14.78195   14.665553\n",
      " 14.709091  14.387574  14.215375  14.20911   14.66388   14.276891\n",
      " 14.558268  14.456858  14.712458  14.26174  ]\n",
      "Step 270, Loss: [14.365618  14.130665  14.1213455 14.518171  14.291027  14.516843\n",
      " 14.529965  14.174924  14.3065    14.354269  14.524398  14.253082\n",
      " 14.605457  14.477359  14.346653  14.1852455]\n",
      "Step 280, Loss: [14.615197 14.065308 14.439302 14.856053 14.716782 14.222584 14.174753\n",
      " 14.58296  14.412648 14.353933 14.240078 14.493788 14.335209 14.1981\n",
      " 13.947806 14.957406]\n",
      "Step 290, Loss: [14.597189 14.227002 14.211461 14.654792 14.598653 14.346969 14.47592\n",
      " 14.591511 14.030126 14.527686 14.353803 14.381622 14.468877 14.655128\n",
      " 14.372741 14.151361]\n",
      "Step 300, Loss: [14.228039  14.140532  14.22418   14.2354145 14.252323  14.0896225\n",
      " 14.446744  14.366872  14.363993  14.137693  14.058786  14.619142\n",
      " 14.314867  14.157655  14.328138  14.423127 ]\n",
      "Step 310, Loss: [14.356705  14.279533  14.550213  13.976704  14.282972  14.250082\n",
      " 14.842058  14.277985  13.881275  14.600622  14.083766  14.219125\n",
      " 14.135659  14.484293  15.0913925 14.244463 ]\n",
      "Step 320, Loss: [14.019377 14.297151 14.281341 14.792226 14.473979 14.050823 14.555258\n",
      " 14.121551 14.79735  14.5168   14.500431 14.487122 14.230702 14.169732\n",
      " 14.801377 14.577203]\n",
      "Step 330, Loss: [14.538611  14.367681  14.255646  14.060727  14.397315  14.282798\n",
      " 14.444865  14.403611  14.306795  14.572281  14.29344   14.894005\n",
      " 14.142379  14.1626835 14.566788  14.37313  ]\n",
      "Step 340, Loss: [14.320465 14.407595 14.211998 14.332108 14.387749 14.047197 14.065\n",
      " 14.490255 14.333202 14.777471 14.408312 14.009038 13.976358 14.156468\n",
      " 14.658328 14.340398]\n",
      "Step 350, Loss: [14.268272  14.023295  14.3193445 14.36519   14.834639  14.20633\n",
      " 14.06482   14.4283905 14.391255  13.945713  14.361288  14.842347\n",
      " 14.188434  14.347435  13.970107  14.301224 ]\n",
      "Step 360, Loss: [14.533581 14.205267 14.183731 14.618135 14.359751 14.08097  14.638505\n",
      " 14.291135 14.141827 13.963912 14.5006   14.402304 14.411568 14.384743\n",
      " 14.258269 14.529821]\n",
      "Step 370, Loss: [14.316278 14.464769 14.212974 14.266707 14.30158  14.092957 14.65665\n",
      " 14.23654  14.499866 14.409749 14.337913 14.32631  14.246823 14.485889\n",
      " 14.355559 14.516716]\n",
      "Step 380, Loss: [14.254779 14.843138 14.842861 14.372902 14.13288  14.578676 14.45733\n",
      " 14.477113 14.610834 14.306748 14.10248  14.284036 14.285648 14.496276\n",
      " 14.192522 14.420693]\n",
      "Step 390, Loss: [14.565982 14.180822 14.315279 14.373934 13.979951 14.10734  14.329015\n",
      " 14.004656 14.688346 14.500675 14.574678 14.152768 14.108816 14.400405\n",
      " 14.410963 14.176904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willy\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    ")\n",
    "\n",
    "# \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'E:\\Codes\\CV train\\dataset\\train',  # \n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "# \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    r'E:\\Codes\\CV train\\dataset\\TrashBox',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "# \n",
    "teacher_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = teacher_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "teacher_model = Model(teacher_model.input, x)\n",
    "teacher_model.trainable = False\n",
    "\n",
    "# \n",
    "student_model = MobileNetV2(alpha=0.35, weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = student_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "student_model = Model(student_model.input, x)\n",
    "for layer in student_model.layers:\n",
    "    layer.trainable = False  # \n",
    "\n",
    "# \n",
    "def distillation_loss(y_true, y_pred, teacher_logits, temperature=5.0, alpha=0.5):\n",
    "    teacher_soft = K.softmax(teacher_logits / temperature)\n",
    "    student_soft = K.softmax(y_pred / temperature)\n",
    "    distill_loss = K.categorical_crossentropy(teacher_soft, student_soft) * (temperature ** 2)\n",
    "    student_loss = K.categorical_crossentropy(y_true, y_pred)\n",
    "    return alpha * distill_loss + (1 - alpha) * student_loss\n",
    "\n",
    "# \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "student_model.compile(optimizer=optimizer, loss=lambda y_true, y_pred: distillation_loss(y_true, y_pred, teacher_model.output))\n",
    "\n",
    "def train_with_distillation(epochs=10):\n",
    "    steps_per_epoch = train_generator.samples // 16\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for step, (x_batch, y_batch) in enumerate(train_generator):\n",
    "            if step >= steps_per_epoch:  # \n",
    "                break\n",
    "            with tf.GradientTape() as tape:\n",
    "                student_logits = student_model(x_batch, training=True)\n",
    "                teacher_logits = teacher_model(x_batch, training=False)\n",
    "                loss = distillation_loss(y_batch, student_logits, teacher_logits)\n",
    "            grads = tape.gradient(loss, student_model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
    "            if step % 10 == 0:\n",
    "                print(f\"Step {step}, Loss: {loss.numpy()}\")\n",
    "\n",
    "train_with_distillation(epochs=10)\n",
    "student_model.save('distilled_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
